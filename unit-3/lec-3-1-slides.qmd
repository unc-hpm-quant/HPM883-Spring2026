---
title: "Introduction to Machine Learning"
subtitle: "Unit 3.1"
author: "Sean Sylvia"
format:
  revealjs:
    theme: default
    slide-number: true
    chalkboard: true
    transition: fade
    progress: true
    incremental: false
    toc: false
    scrollable: false
    smaller: false
    footer: "UNC HPM 883 - Advanced Quantitative Methods"
draft: true
---

# Introduction to Machine Learning

## Loads of recent advances in Machine Learning & other Types of AI...

Obviously, ChatGPT & other Large Language Models (LLMs) are the most visible ... but many other advances...

All enabled by large amounts of data, computing power, and advances in methods to **predict** or **learn** patterns in data.

## Machine Translation

![](media/Translation.png)

## Self-Driving Cars

![](media/self-driving.png)

## Robots for Housework

![](media/housework.png)

## ...or imposing martial law

![](media/martial.png)

## or even governing

![](media/govern.png)

## What is machine learning?

-   Traditional OLS struggles with thousands of features or highly nonlinear relationships.\
-   ML can more flexibly uncover predictive patterns for tasks like readmission risk, resource targeting, or disease onset.

---
title: "Introduction to Machine Learning"
author: "Your Name"
date: March 2025
format:
  revealjs:
    theme: default
    slide-number: true
    chalkboard: true
    transition: fade
    progress: true
    incremental: false
    toc: false
    scrollable: false
    smaller: false
    footer: "UNC HPM 883 - Experimental & Quantitative Methods"
---

## 1. Introduction & Motivation

::: incremental
-   **From Sci-Fi to Daily Life**
    -   We often imagine AI like in *Ex Machina*—futuristic robots passing as humans.\
    -   But *modern* machine learning is already in your pocket:
        -   **Facebook** recognizing friends in photos\
        -   **Google Translate** scanning text and translating on the fly\
        -   **Self-driving cars** detecting obstacles and avoiding collisions
-   **Why This Matters for Health Policy**
    -   Healthcare settings generate enormous amounts of data (EHR, administrative claims, sensor data).\
    -   Traditional OLS struggles with thousands of features or highly nonlinear relationships.\
    -   ML can more flexibly uncover predictive patterns for tasks like readmission risk, resource targeting, or disease onset.\
:::

::: notes
Mention the powerful day-to-day examples: face recognition, real-time translation, partial self-driving. Emphasize how these examples come from the same machine learning concepts that can be harnessed in health economics (predicting outcomes, segmenting populations, etc.).
:::

------------------------------------------------------------------------

## 2. ML Essentials: Supervised Learning

::: incremental
-   **Supervised Learning**: Learn a function (f) from labeled data ((X_i, Y_i))
    -   We choose a **loss function** (e.g., MSE for regression).\
    -   The goal is to predict (Y) for new, unseen (X).
-   **Cucumber Classification Example**
    -   *Transcripts mention a story of a family in Japan automating cucumber sorting.*\
    -   **Old approach**: Hard-coded rules about color, shape.\
    -   **New approach**: Train a model on labeled images → The ML system figures out patterns.
-   **Implications for Health**
    -   Similarly, we can feed in medical images or extensive patient data and let an ML algorithm detect subtle features predictive of outcomes.\
:::

::: fragment
**Remember**: This is not about interpreting *why* the algorithm picks certain features but about *accuracy* in predicting the outcome.
:::

------------------------------------------------------------------------

## 3. Focus on Prediction vs. Causal Inference

::: incremental
-   **ML’s Core Strength**
    -   Minimizing out-of-sample error for (\hat{Y}).\
    -   This is critical for tasks where we just need *the best guess* of a target variable.
-   **But…**
    -   It doesn’t guarantee stable or unbiased coefficient estimates.\
    -   “*Beta-hard*” vs. “*Y-hard*” distinction from transcripts:
        -   *Beta-hard tasks*: Causal or structural inference.\
        -   *Y-hard tasks*: Focused purely on predictive performance.
-   **Example**:
    -   Predicting credit default from a large set of features doesn’t necessarily tell us *which* variable causes default—it just flags risk.\
:::

::: notes
Draw from transcript references to differences in “beta-hat” (interpretation, structural causal parameters) versus “y-hat” (pure prediction). The credit default example underscores how correlated features can still yield accurate predictions even if the coefficients aren’t interpretable.
:::

------------------------------------------------------------------------

## 4. The Bias–Variance Trade-Off

::: incremental
-   **Overfitting vs. Underfitting**
    -   **Overfit**: The model memorizes noise, performs poorly on new data.\
    -   **Underfit**: Model too simple, high bias, misses real structure.
-   **Polynomial Example** (from transcripts)
    -   Fitting polynomials of degrees 2, 4, 10… and seeing test MSE behavior.\
    -   We want a “sweet spot” that captures the signal but not the noise.
-   **Cross-Validation**
    -   Partition data into training/validation (or do k-fold).\
    -   **Key**: Choose complexity (e.g., polynomial degree) that minimizes out-of-sample error.\
:::

::: fragment
![Placeholder: Overfit vs. Underfit Polynomials](assets/overfit-underfit.png)
:::

------------------------------------------------------------------------

## 5. Regularization: LASSO, Ridge, Elastic Net

::: incremental
1.  **Why Regularize?**
    -   With many features (think 2000+ labs & comorbidities in a hospital dataset), OLS can overfit or produce huge coefficient variance.
2.  **LASSO**
    -   (\min \sum (y - x\beta)\^2 + \lambda \sum\|\beta\_j\|)\
    -   Sets some coefficients *exactly zero* → “capitalist” approach\
    -   Great for feature selection, but watch out for omitted-variable bias if correlated features exist.
3.  **Ridge**
    -   (\min \sum (y - x\beta)\^2 + \lambda \sum \beta\_j\^2)\
    -   Shrinks all coefficients → “socialist,” no exact zeros.
4.  **Elastic Net**
    -   Mix of both; (\alpha \|\beta\|\_1 + (1-\alpha)\|\beta\|\_2\^2).\
:::

::: fragment
**Cross-validation** typically used to pick (\lambda). The transcripts mention how LASSO can be *unstable* when multiple variables are correlated.
:::

------------------------------------------------------------------------

## LASSO & Coefficient Instability

::: incremental
-   **Transcript Example**:
    -   If `BEDRMS` and `BATHS` are both strongly correlated with house price, LASSO might select one or the other arbitrarily.\
    -   Re-running LASSO on slightly different training sets can flip which variable is chosen.
-   **Implication**
    -   The model’s *predictive performance* might stay good.\
    -   But the selected variables are not necessarily “the true drivers.”\
:::

------------------------------------------------------------------------

## 6. Tree-Based Methods

::: incremental
-   **Decision Trees**
    -   Recursively split data (like “Is `BATHS` ≤ 1.5?”).\
    -   If grown too deep → overfit. Prune or limit depth to reduce variance.\
    -   Interpretable: “If you see a node, you know which variable & threshold used.”
-   **Regression Trees** for continuous outcomes
    -   e.g., Predicting log house value from transcripts: splits on \# bathrooms, \# rooms, year built, etc.
-   **Random Forests**
    -   Bagging many trees on bootstrap samples + random feature subsets.\
    -   Usually yields stable, accurate predictions.\
    -   OOB (out-of-bag) error as built-in performance estimate.\
:::

::: fragment
“Forest = an ensemble that reduces variance by averaging many uncorrelated (or weakly correlated) trees.”
:::

------------------------------------------------------------------------

## 7. Real-World Example: Poverty Targeting

::: incremental
-   **From the Transcripts**:
    -   Predicting household consumption from characteristics to identify who is poor.\
    -   A tree-based or LASSO approach can rank families most in need for a subsidy.
-   **In Practice**
    -   Government agencies (e.g., social service departments) often have partial data on household size, assets, location.\
    -   ML can guess consumption/income more accurately than basic linear models.
-   **Important Caveat**
    -   This is purely for *predicting who is poor*, not claiming what *causes* poverty.\
:::

------------------------------------------------------------------------

## 8. When ML Is Enough & When We Need More

::: incremental
-   **Pure Prediction Scenarios**
    -   Triage or resource allocation: We only need a good risk score.\
    -   Implementation: Create a threshold, direct resources to high-score folks.\
    -   The transcripts mention this approach for tax audits, loan default, self-driving decisions.
-   **Causal Inference**
    -   If we want the effect of an intervention, ML can’t solve hidden confounding alone.\
    -   Must combine ML with robust design (RCT, difference-in-differences, etc.).
-   **Takeaway**
    -   ML is amazing for big data + complex patterns → “Which units are at risk?”\
    -   For “Why?” or “What if we changed X?” → specialized approaches (Double ML, partial IDs, etc.).\
:::

------------------------------------------------------------------------

## 9. Practical Tips for Implementation

::: incremental
1.  **Choose Software**
    -   `glmnet` for LASSO/Ridge\
    -   `rpart`, `randomForest`, or `grf` for tree methods\
    -   `caret` or `tidymodels` frameworks for consistent workflows
2.  **Data Splitting**
    -   Keep a final holdout set *untouched* for unbiased performance.\
    -   k-fold cross-validation for hyperparameter tuning.
3.  **Watch Out for Overfitting**
    -   Don’t repeatedly peek at your test set to tune.\
    -   Use separate *validation* vs. *test* sets.
4.  **Document**
    -   Seeds, code versions, transformations.\
    -   Maintain reproducibility logs.\
:::

------------------------------------------------------------------------

## 10. Summary & Key Takeaways

::: incremental
1.  **ML** is outstanding for *prediction* tasks in large or complex data.\
2.  **Cross-validation** is critical to handle overfitting vs. underfitting.\
3.  **LASSO & Ridge**: Solve high-dimensional problems but can create bias in coefficients.\
4.  **Decision Trees & Forests**: Nonlinear, flexible, strong performance, less interpretability.\
5.  **Prediction (**\neq) Causation. For causal insights, we still need strong designs (RCT, etc.).\
6.  **Practical**: Use the transcripts’ examples (cucumber, credit, poverty) as analogies in health contexts.\
:::

------------------------------------------------------------------------

## References & Next Steps

::: incremental
-   **Key Readings**
    -   James et al. (2013): *An Introduction to Statistical Learning*\
    -   Hastie, Tibshirani, Friedman: *The Elements of Statistical Learning*\
    -   Mullainathan & Spiess (2017): “Machine Learning: An Applied Econometric Approach,” *JEP*
-   **Coming Soon**
    -   Integrating ML with experimental/quasi-experimental methods\
    -   Double Machine Learning for partial out confounders\
    -   Causal Forests for heterogeneity in treatment effects
:::

------------------------------------------------------------------------

## Appendix

::: incremental
-   **More detail from transcripts**:
    1.  The cucumber farm in Japan example\
    2.  The “Facebook friend recognition / Google Translate” references\
    3.  Potential insight about self-driving cars framing a supervised learning approach
-   **Extended Code Snippets**
    -   LASSO path plots\
    -   Cross-validation loops for polynomial degrees\
    -   Random forest variable importance examples
-   **Figures**
    -   Bias–variance decomposition chart\
    -   Polynomial degrees vs. test error curves\
:::

::: notes
Wrap up with direct references to the transcripts, reminding students these real-life examples highlight ML’s predictive success and the continuing caution around interpretive leaps.
:::