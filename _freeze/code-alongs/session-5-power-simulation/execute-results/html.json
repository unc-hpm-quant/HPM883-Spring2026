{
  "hash": "b47bb40cb12e622c278348503089104c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Code-Along: Power Simulation with DeclareDesign\"\nsubtitle: \"Session 5: Statistical Conclusion Validity & Power\"\nauthor: \"Sean Sylvia\"\ndate: \"January 21, 2026\"\nformat:\n  html:\n    toc: true\n    code-tools: true\nexecute:\n  eval: true\n  echo: true\n---\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DeclareDesign)\nlibrary(data.table)\nlibrary(ggplot2)\nset.seed(883)\n```\n:::\n\n\n## Part 1: A Simple RCT Design\n\nLet's declare a simple randomized controlled trial for a chronic disease intervention.\n\n**Context:** Testing whether enhanced care coordination reduces HbA1c levels in diabetic patients.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Parameters\nN <- 200\ntreatment_effect <- -0.5  # 0.5% reduction in HbA1c\nsd_outcome <- 1.2\n\n# Declare the design\ndesign <-\n  declare_model(\n    N = N,\n    U = rnorm(N, 0, sd_outcome),\n    Y_Z_0 = 8.5 + U,\n    Y_Z_1 = 8.5 + treatment_effect + U\n  ) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_assignment(Z = complete_ra(N)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, inquiry = \"ATE\", .method = lm_robust)\n\n# Preview\ndesign\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nResearch design declaration summary\n\nStep 1 (model): declare_model(N = N, U = rnorm(N, 0, sd_outcome), Y_Z_0 = 8.5 + U, Y_Z_1 = 8.5 + treatment_effect + U) \n\nStep 2 (inquiry): declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) -------------------\n\nStep 3 (assignment): declare_assignment(Z = complete_ra(N)) --------------------\n\nStep 4 (measurement): declare_measurement(Y = reveal_outcomes(Y ~ Z)) ----------\n\nStep 5 (estimator): declare_estimator(Y ~ Z, inquiry = \"ATE\", .method = lm_robust) \n\nRun of the design:\n\n inquiry estimand estimator term estimate std.error statistic p.value conf.low\n     ATE     -0.5 estimator    Z   -0.196     0.173     -1.13   0.259   -0.538\n conf.high  df outcome\n     0.146 198       Y\n\nParameters saved in design environments:\n\n             name value_str steps\n                N       200     1\n       sd_outcome       1.2     1\n treatment_effect      -0.5     1\n```\n\n\n:::\n:::\n\n\n## Part 2: Draw Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Draw one realization\nsim_data <- draw_data(design)\nhead(sim_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   ID          U    Y_Z_0    Y_Z_1 Z        Y\n1 001 -0.6256922 7.874308 7.374308 1 7.374308\n2 002 -0.3871397 8.112860 7.612860 0 8.112860\n3 003  0.8156586 9.315659 8.815659 0 9.315659\n4 004  0.3599849 8.859985 8.359985 1 8.359985\n5 005 -1.4890095 7.010991 6.510991 0 7.010991\n6 006 -1.0035756 7.496424 6.996424 0 7.496424\n```\n\n\n:::\n\n```{.r .cell-code}\n# Estimate\ndraw_estimates(design)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  estimator term   estimate std.error statistic      p.value  conf.low\n1 estimator    Z -0.7718248 0.1725495 -4.473063 1.298313e-05 -1.112095\n   conf.high  df outcome inquiry\n1 -0.4315541 198       Y     ATE\n```\n\n\n:::\n:::\n\n\n## Part 3: Diagnose the Design\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run 200 simulations\ndiagnosis <- diagnose_design(design, sims = 200)\ndiagnosis\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nResearch design diagnosis based on 200 simulations. Diagnosis completed in 1 secs. Diagnosand estimates with bootstrapped standard errors in parentheses (100 replicates).\n\n Design Inquiry Estimator Outcome Term N Sims Mean Estimand Mean Estimate\n design     ATE estimator       Y    Z    200         -0.50         -0.53\n                                                     (0.00)        (0.01)\n   Bias SD Estimate   RMSE  Power Coverage\n  -0.03        0.16   0.16   0.88     0.96\n (0.01)      (0.01) (0.01) (0.03)   (0.01)\n```\n\n\n:::\n:::\n\n\n**Key questions:**\n- What is the power?\n- Is the estimator unbiased?\n- Is coverage close to 95%?\n\n## Part 4: Power Curve\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Vary sample size\nsample_sizes <- c(50, 100, 150, 200, 300, 400)\n\npower_results <- lapply(sample_sizes, function(n) {\n  d <- redesign(design, N = n)\n  diag <- diagnose_design(d, sims = 100)\n  data.frame(N = n, power = diag$diagnosands$power)\n})\n\npower_df <- do.call(rbind, power_results)\n\nggplot(power_df, aes(x = N, y = power)) +\n  geom_line() + geom_point(size = 3) +\n  geom_hline(yintercept = 0.8, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Power by Sample Size\", y = \"Power\", x = \"N\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](session-5-power-simulation_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n## Part 5: MDE Calculation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Analytical MDE\ncalculate_mde <- function(n, sigma, alpha = 0.05, power = 0.80) {\n  t_a <- qt(1 - alpha/2, n - 2)\n  t_b <- qt(power, n - 2)\n  se <- sigma * sqrt(4/n)  # Equal allocation\n  (t_a + t_b) * se\n}\n\nmde_200 <- calculate_mde(200, sd_outcome)\ncat(\"MDE with N=200:\", round(mde_200, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMDE with N=200: 0.478 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Expected effect:\", abs(treatment_effect), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nExpected effect: 0.5 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Powered?\", abs(treatment_effect) > mde_200, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPowered? TRUE \n```\n\n\n:::\n:::\n\n\n## Your Turn\n\nModify the design to test:\n1. What happens with a smaller effect size (0.3)?\n2. What if the outcome has more variance (SD = 2.0)?\n3. How much does blocking by clinic help?\n\n---\n\n*Continue to Problem Set 1 for the full assignment.*\n",
    "supporting": [
      "session-5-power-simulation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}