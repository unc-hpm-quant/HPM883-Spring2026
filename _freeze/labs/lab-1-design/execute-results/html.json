{
  "hash": "0633ecc204b19865ecf380fd4dcb967f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Lab 1\nsubtitle: \"Experimental Design & Power with DeclareDesign\"\nauthor: \"Sean Sylvia\"\ndate: \"2025-12-25\"\nslug: \"lab-1\"\ncategories: [Lab, Experimental Design, Power]\ndescription: \"Design, diagnose, and redesign experiments using the MIDA framework and DeclareDesign.\"\nformat:\n  html:\n    toc: true\n    toc-depth: 2\n    code-tools: true\neditor: visual\nexecute:\n  eval: false\n---\n\n## Overview and Learning Objectives\n\nIn this lab, you will apply the **MIDA framework** (Model-Inquiry-Data-Answer) to design and diagnose randomized experiments. You will:\n\n1.  **Declare** a complete experimental design using DeclareDesign\n2.  **Diagnose** your design's statistical properties (bias, power, coverage)\n3.  **Redesign** to compare simple vs. blocked randomization\n4.  **Analyze** trade-offs between sample size, effect size, and power\n\nBy the end of this lab, you will have practical experience with:\n\n-   Thinking systematically about research design using the MIDA framework\n-   Using `DeclareDesign`, `fabricatr`, and `randomizr` for experimental design\n-   Conducting power analysis by simulation\n-   Understanding when blocking improves (or doesn't improve) power\n-   Calculating Minimum Detectable Effects (MDEs)\n\n------------------------------------------------------------------------\n\n## The Healthy Futures Clinic Network\n\n### Background\n\nYou have been hired as a research consultant by the **Healthy Futures Clinic Network**, a consortium of 20 community health clinics serving underserved populations. The network wants to evaluate a **chronic disease management intervention** that provides enhanced care coordination for patients with Type 2 diabetes.\n\nThe intervention includes: - Weekly check-ins with a care coordinator - Text message medication reminders - Quarterly home visits\n\n**Primary outcome:** HbA1c levels (hemoglobin A1c, a measure of blood glucose control)\n\n**Key parameters:** - **Baseline HbA1c:** Mean = 8.5%, SD = 1.2% - **Expected treatment effect:** 0.5% reduction in HbA1c - **Clinically meaningful difference:** 0.3% reduction - **Budget constraint:** Can enroll up to 400 patients total - **Individual randomization** is ethically and practically feasible\n\nYour task: Design an experiment that can detect whether the intervention works.\n\n------------------------------------------------------------------------\n\n## Part 1: Getting Started with DeclareDesign\n\nFirst, let's install and load the required packages:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Install if needed\nif (!require(\"DeclareDesign\")) install.packages(\"DeclareDesign\")\nif (!require(\"data.table\")) install.packages(\"data.table\")\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\n\n# Load libraries\nlibrary(DeclareDesign)\nlibrary(data.table)\nlibrary(ggplot2)\n\n# Set seed for reproducibility\nset.seed(883)\n```\n:::\n\n\n### The MIDA Framework\n\nEvery research design has four components:\n\n| Component | Question | Example |\n|--------------------------|------------------------|----------------------|\n| **M**odel | What is the data generating process? | HbA1c \\~ treatment + covariates + error |\n| **I**nquiry | What is the estimand? | Average Treatment Effect (ATE) |\n| **D**ata strategy | How do we collect data? | Random assignment, N=400 |\n| **A**nswer strategy | How do we estimate? | Difference-in-means, regression |\n\nLet's declare each component step by step.\n\n------------------------------------------------------------------------\n\n## Part 2: Declaring Your Design\n\n### Step 1: Declare the Model\n\nThe **model** defines the potential outcomes for each unit. This is your hypothesis about how the world works.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define simulation parameters\nN <- 400                    # Total sample size\nbaseline_hba1c <- 8.5       # Mean baseline HbA1c (%)\nsd_hba1c <- 1.2             # Standard deviation\ntreatment_effect <- -0.5    # Expected effect (reduction)\n\n# Declare the model\nmodel <- declare_model(\n  N = N,\n  # Individual-level error (unexplained variation)\n  U = rnorm(N, mean = 0, sd = sd_hba1c),\n  # Potential outcomes\n  Y_Z_0 = baseline_hba1c + U,          # Control outcome\n  Y_Z_1 = baseline_hba1c + treatment_effect + U  # Treatment outcome\n)\n\n# Preview the model\ndraw_data(model) |> head()\n```\n:::\n\n\n::: callout-note\n## Task 1: Understand the Model\n\n1.  What does `U` represent in this model?\n2.  Why do we add `U` to both potential outcomes?\n3.  What assumption are we making about treatment effect heterogeneity?\n:::\n\n### Step 2: Declare the Inquiry\n\nThe **inquiry** defines what we want to learn—the estimand.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Declare the inquiry: Average Treatment Effect\ninquiry <- declare_inquiry(\n  ATE = mean(Y_Z_1 - Y_Z_0)\n)\n```\n:::\n\n\n::: callout-note\n## Task 2: What's the True ATE?\n\nBased on our model, what is the true Average Treatment Effect? (Hint: It's deterministic given our setup.)\n:::\n\n### Step 3: Declare the Data Strategy\n\nThe **data strategy** specifies how we collect data—sampling and treatment assignment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Declare simple random assignment\nassignment <- declare_assignment(\n  Z = complete_ra(N, prob = 0.5)\n)\n\n# Declare measurement (reveal potential outcomes)\nmeasurement <- declare_measurement(\n  Y = reveal_outcomes(Y ~ Z)\n)\n```\n:::\n\n\n### Step 4: Declare the Answer Strategy\n\nThe **answer strategy** specifies how we estimate the treatment effect.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Declare the estimator: difference-in-means\nestimator <- declare_estimator(\n  Y ~ Z,\n  inquiry = \"ATE\",\n  .method = lm_robust,\n  label = \"Difference-in-Means\"\n)\n```\n:::\n\n\n### Step 5: Combine into a Complete Design\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Combine all components\ndesign <- model + inquiry + assignment + measurement + estimator\n\n# View the design\ndesign\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 3: Diagnosing Your Design\n\nNow that we have declared our design, let's **diagnose** its statistical properties by simulating many realizations.\n\n### Step 1: Run Simulations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Diagnose the design with 500 simulations\ndiagnosis <- diagnose_design(design, sims = 500)\n\n# View the diagnosis\ndiagnosis\n```\n:::\n\n\n### Key Diagnosands\n\n| Diagnosand   | Definition                 | Target |\n|--------------|----------------------------|--------|\n| **Bias**     | E\\[estimate\\] - true value | 0      |\n| **RMSE**     | Root mean squared error    | Low    |\n| **Power**    | P(reject H₀ \\| H₁ true)    | ≥ 0.80 |\n| **Coverage** | P(CI contains true value)  | 0.95   |\n\n::: callout-note\n## Task 3: Interpret the Diagnosis\n\n1.  What is the estimated power of this design?\n2.  Is the difference-in-means estimator unbiased?\n3.  Is the 95% CI coverage close to 0.95?\n:::\n\n### Step 2: Visualize Power Across Sample Sizes\n\nLet's see how power changes with sample size:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create designs with different sample sizes\nsample_sizes <- seq(100, 600, by = 50)\n\ndesigns <- lapply(sample_sizes, function(n) {\n  declare_model(\n    N = n,\n    U = rnorm(N, mean = 0, sd = sd_hba1c),\n    Y_Z_0 = baseline_hba1c + U,\n    Y_Z_1 = baseline_hba1c + treatment_effect + U\n  ) +\n  inquiry +\n  declare_assignment(Z = complete_ra(N, prob = 0.5)) +\n  measurement +\n  estimator\n})\n\n# Diagnose all designs\ndiagnoses <- diagnose_designs(designs, sims = 200)\n\n# Extract power estimates\npower_results <- data.table(\n  N = sample_sizes,\n  Power = sapply(diagnoses, function(d) d$diagnosands$power[1]),\n  SE = sapply(diagnoses, function(d) d$diagnosands$se_power[1])\n)\n\n# Plot power curve\nggplot(power_results, aes(x = N, y = Power)) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 3) +\n  geom_ribbon(aes(ymin = Power - 1.96*SE, ymax = Power + 1.96*SE), alpha = 0.2) +\n  geom_hline(yintercept = 0.80, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Power by Sample Size\",\n    subtitle = paste(\"Effect size:\", treatment_effect, \"| SD:\", sd_hba1c),\n    x = \"Total Sample Size\",\n    y = \"Statistical Power\"\n  ) +\n  theme_minimal() +\n  scale_y_continuous(limits = c(0, 1))\n```\n:::\n\n\n::: callout-note\n## Task 4: Find the Required Sample Size\n\nBased on the power curve, approximately what sample size is needed to achieve 80% power? Is our budget of 400 patients sufficient?\n:::\n\n------------------------------------------------------------------------\n\n## Part 4: Comparing Simple vs. Blocked Randomization\n\nBlocking can reduce variance and increase power when blocks explain variation in outcomes. Let's compare designs.\n\n### Step 1: Add a Blocking Variable\n\nSuppose we know each patient's clinic, and clinics vary in their patient populations:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Number of clinics\nn_clinics <- 20\n\n# Declare model with clinic effects\nmodel_blocked <- declare_model(\n  N = N,\n  # Clinic assignment\n  clinic_id = sample(1:n_clinics, N, replace = TRUE),\n  # Clinic-level effect (some clinics have sicker patients)\n  clinic_effect = rnorm(n_clinics, mean = 0, sd = 0.5)[clinic_id],\n  # Individual-level error\n  U = rnorm(N, mean = 0, sd = 1.0),\n  # Potential outcomes\n  Y_Z_0 = baseline_hba1c + clinic_effect + U,\n  Y_Z_1 = baseline_hba1c + treatment_effect + clinic_effect + U\n)\n```\n:::\n\n\n### Step 2: Declare Simple vs. Blocked Assignment\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simple random assignment\nassignment_simple <- declare_assignment(\n  Z = complete_ra(N, prob = 0.5),\n  label = \"Simple\"\n)\n\n# Blocked random assignment (block by clinic)\nassignment_blocked <- declare_assignment(\n  Z = block_ra(blocks = clinic_id),\n  label = \"Blocked\"\n)\n```\n:::\n\n\n### Step 3: Compare Designs\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simple randomization design\ndesign_simple <- model_blocked + inquiry + assignment_simple + measurement + estimator\n\n# Blocked randomization design\ndesign_blocked <- model_blocked + inquiry + assignment_blocked + measurement +\n  declare_estimator(\n    Y ~ Z + factor(clinic_id),  # Include clinic fixed effects\n    inquiry = \"ATE\",\n    .method = lm_robust,\n    label = \"Blocked + FE\"\n  )\n\n# Diagnose both\ncomparison <- diagnose_designs(\n  list(Simple = design_simple, Blocked = design_blocked),\n  sims = 500\n)\n\n# View comparison\ncomparison\n```\n:::\n\n\n::: callout-note\n## Task 5: Compare the Designs\n\n1.  Which design has higher power?\n2.  What is the difference in RMSE between designs?\n3.  Why does blocking help (or not help) in this case?\n:::\n\n------------------------------------------------------------------------\n\n## Part 5: Minimum Detectable Effect (MDE)\n\nThe **Minimum Detectable Effect** is the smallest effect you can detect with a given power level. It's a key design parameter.\n\n### Analytical MDE Formula\n\nFor a simple two-arm RCT with equal allocation:\n\n$$MDE = (t_{1-\\alpha/2} + t_{1-\\beta}) \\times \\sqrt{\\frac{\\sigma^2}{n_T} + \\frac{\\sigma^2}{n_C}}$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MDE calculation function\ncalculate_mde <- function(n_total, sigma, alpha = 0.05, power = 0.80, prop_treated = 0.5) {\n  n_T <- n_total * prop_treated\n  n_C <- n_total * (1 - prop_treated)\n\n  t_alpha <- qt(1 - alpha/2, df = n_total - 2)\n  t_beta <- qt(power, df = n_total - 2)\n\n  se <- sqrt(sigma^2 / n_T + sigma^2 / n_C)\n  mde <- (t_alpha + t_beta) * se\n\n  return(mde)\n}\n\n# Calculate MDE for our design\nmde_400 <- calculate_mde(n_total = 400, sigma = sd_hba1c)\ncat(\"MDE with N=400:\", round(mde_400, 3), \"% HbA1c\\n\")\ncat(\"Expected effect:\", treatment_effect, \"% HbA1c\\n\")\ncat(\"Powered to detect expected effect?\", abs(treatment_effect) > mde_400, \"\\n\")\n```\n:::\n\n\n### MDE by Sample Size\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate MDE for different sample sizes\nmde_results <- data.table(\n  N = seq(100, 800, by = 50),\n  MDE = sapply(seq(100, 800, by = 50), function(n) calculate_mde(n, sigma = sd_hba1c))\n)\n\n# Plot MDE curve\nggplot(mde_results, aes(x = N, y = MDE)) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 2) +\n  geom_hline(yintercept = abs(treatment_effect), linetype = \"dashed\", color = \"blue\",\n             linewidth = 1) +\n  geom_hline(yintercept = 0.3, linetype = \"dotted\", color = \"red\") +\n  annotate(\"text\", x = 750, y = abs(treatment_effect) + 0.05,\n           label = \"Expected Effect\", color = \"blue\") +\n  annotate(\"text\", x = 750, y = 0.35,\n           label = \"Clinical Threshold\", color = \"red\") +\n  labs(\n    title = \"Minimum Detectable Effect by Sample Size\",\n    subtitle = paste(\"SD =\", sd_hba1c, \"| α = 0.05 | Power = 80%\"),\n    x = \"Total Sample Size\",\n    y = \"MDE (% HbA1c)\"\n  ) +\n  theme_minimal()\n```\n:::\n\n\n::: callout-note\n## Task 6: MDE Interpretation\n\n1.  With N=400, can we detect the expected effect of 0.5%?\n2.  Can we detect the clinically meaningful threshold of 0.3%?\n3.  What sample size would we need to detect an effect of 0.3%?\n:::\n\n------------------------------------------------------------------------\n\n## Part 6: Variance Reduction with Covariates\n\n### Lin (2013) Regression Adjustment\n\nWe can improve power by adjusting for baseline covariates. The key insight from Lin (2013):\n\n1.  **Center** covariates at their means\n2.  **Include** covariate × treatment interactions\n3.  This **guarantees** variance reduction (never hurts!)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add baseline HbA1c as a covariate\nmodel_with_baseline <- declare_model(\n  N = N,\n  clinic_id = sample(1:n_clinics, N, replace = TRUE),\n  # Baseline HbA1c (observed pre-treatment)\n  baseline_hba1c_measured = baseline_hba1c + rnorm(N, 0, 0.5),\n  # Individual effect (correlated with baseline)\n  U = 0.6 * (baseline_hba1c_measured - baseline_hba1c) + rnorm(N, mean = 0, sd = 0.8),\n  # Potential outcomes\n  Y_Z_0 = baseline_hba1c + U,\n  Y_Z_1 = baseline_hba1c + treatment_effect + U\n)\n\n# Unadjusted estimator\nestimator_unadj <- declare_estimator(\n  Y ~ Z,\n  inquiry = \"ATE\",\n  .method = lm_robust,\n  label = \"Unadjusted\"\n)\n\n# Lin-adjusted estimator\n# Center baseline and include interaction\nestimator_lin <- declare_estimator(\n  Y ~ Z * I(baseline_hba1c_measured - mean(baseline_hba1c_measured)),\n  inquiry = \"ATE\",\n  .method = lm_robust,\n  term = \"Z\",\n  label = \"Lin-adjusted\"\n)\n\n# Compare designs\ndesign_unadj <- model_with_baseline + inquiry + assignment_simple + measurement + estimator_unadj\ndesign_lin <- model_with_baseline + inquiry + assignment_simple + measurement + estimator_lin\n\ncomparison_cov <- diagnose_designs(\n  list(Unadjusted = design_unadj, `Lin-Adjusted` = design_lin),\n  sims = 500\n)\n\ncomparison_cov\n```\n:::\n\n\n::: callout-note\n## Task 7: Covariate Adjustment\n\n1.  How much does power improve with Lin adjustment?\n2.  Is the Lin-adjusted estimator still unbiased?\n3.  Why does covariate adjustment work in this case?\n:::\n\n------------------------------------------------------------------------\n\n## Part 7: Your Design Challenge\n\nNow it's your turn to design an experiment for a different health intervention.\n\n### The Challenge\n\nThe Healthy Futures Network is also considering testing a **smoking cessation program**. Here are the parameters:\n\n-   **Outcome:** 6-month abstinence rate (binary: quit or not)\n-   **Baseline quit rate:** 10% (without intervention)\n-   **Expected treatment effect:** 8 percentage point increase (to 18%)\n-   **Clinically meaningful difference:** 5 percentage points\n-   **Budget:** Can enroll up to 500 participants\n\n::: callout-important\n## Task 8: Design the Smoking Cessation Trial\n\nUsing DeclareDesign, create a complete experimental design for this intervention. Your design should:\n\n1.  Declare a model with binary outcomes\n2.  Declare the inquiry (ATE on the probability scale)\n3.  Declare the data strategy (randomization)\n4.  Declare the answer strategy (appropriate for binary outcomes)\n5.  Diagnose the design to assess power\n6.  Report the MDE and whether you're powered to detect the expected effect\n\n**Hints:** - For binary outcomes, use `draw_binary()` in fabricatr or `rbinom()` - The variance of a binary outcome is p(1-p) - Consider whether `lm_robust` or a different estimator is appropriate\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# YOUR CODE HERE\n\n# Hint: Start with the model\nsmoking_model <- declare_model(\n  N = 500,\n  # Define potential outcomes for binary outcome\n  # ...\n)\n\n# Continue with inquiry, assignment, measurement, estimator\n# ...\n\n# Diagnose your design\n# ...\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Submission Instructions\n\n1.  Complete all tasks marked with ::: callout-note\n2.  Write your own design for the smoking cessation trial (Task 8)\n3.  Render your `.qmd` file to HTML\n4.  Submit to Gradescope by **February 2, 2026**\n\nInclude: - All code with `eval: true` so results are visible - Written answers to discussion questions - Your smoking cessation design with diagnosis\n\n------------------------------------------------------------------------\n\n## Additional Resources\n\n### DeclareDesign\n\n-   [DeclareDesign Documentation](https://declaredesign.org/)\n-   [Design Library](https://declaredesign.org/library/)\n-   [Power Analysis Vignette](https://declaredesign.org/r/designlibrary/articles/power.html)\n\n### Readings\n\n-   Blair et al. (2019) — \"Declaring and Diagnosing Research Designs\"\n-   Lin (2013) — \"Agnostic notes on regression adjustments\"\n-   Chernozhukov et al. (2025) — Chapter 3\n\n### R Packages\n\n-   [`DeclareDesign`](https://declaredesign.org/) — Declare, diagnose, redesign\n-   [`estimatr`](https://declaredesign.org/r/estimatr/) — Fast robust estimators\n-   [`fabricatr`](https://declaredesign.org/r/fabricatr/) — Simulate data\n-   [`randomizr`](https://declaredesign.org/r/randomizr/) — Randomization tools",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}