{
  "hash": "ad90393035fde36df2d5428fc71fc0e4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Unit 2.2: Randomization Techniques\"\nauthor: \"Sean Sylvia, Ph.D.\"\ndate: February 25, 2025\nformat:\n  html:\n    toc: true\n    toc-depth: 2\n    code-tools: true\nexecute:\n  warning: false\n  message: false\ndraft: false\n---\n\n\n\n## Introduction\n\nBuilding on our previous discussion of optimal experimental design where we focused on maximizing statistical power under various constraints, today we turn our attention to the art and science of randomization itself. Randomization is the cornerstone of causal inference in experimental research, enabling us to make causal claims by balancing both observable and unobservable characteristics between treatment and control groups. Whereas observational studies must rely on often-questionable assumptions about selection mechanisms, properly randomized experiments provide a foundation for causal inference that is far more credible.\n\nThe power of randomization comes from its ability to create groups that are, in expectation, identical on all characteristics—not just those we can observe and measure, but also on unobservable factors that might influence outcomes. This property allows us to attribute any differences in outcomes between treatment and control groups to the treatment itself, rather than to pre-existing differences between groups.\n\n### Theoretical Foundation: Why Randomization Works\n\nRandomization works because it satisfies three essential conditions:\n\n1.  **Non-zero probability condition**: Each unit has a positive probability of receiving any treatment assignment.\n2.  **Individualism**: The assignment of one unit doesn't depend on the assignments of other units.\n3.  **Unconfoundedness**: The treatment assignment is independent of potential outcomes.\n\nWhen these conditions are met, we can write:\n\n$$E[Y_i(0)|D_i=1] = E[Y_i(0)|D_i=0]$$\n\nThis equation states that the expected untreated potential outcome for those in the treatment group equals the expected untreated potential outcome for those in the control group. In other words, the groups are balanced on the counterfactual outcome we never get to observe for the treatment group. This balance on unobservables is the key to establishing causality.\n\n### Elements Needed for Randomization\n\nBefore discussing specific randomization methods, let's identify what's generally required to implement randomization:\n\n1.  **Sample of units**: The individuals, clusters, or entities to be randomized\n2.  **Allocation ratio**: The proportion of units to assign to each treatment condition\n3.  **Randomization device**: A physical or computational mechanism to generate random assignments\n4.  **Baseline covariates**: (For some approaches) Information on characteristics to balance across groups\n\n### Random Sampling vs. Random Assignment\n\n![Random Sampling vs. Random Assignment](media/SamplingVRandom.png){style=\"float: right; margin-left: 10px; width: 300px;\"}\n\nIt's important to distinguish between two distinct concepts that are sometimes confused:\n\n-   **Random sampling**: The process of selecting units from a population so that each unit has a known probability of selection\n-   **Random assignment**: The process of allocating units to treatment conditions through a random process\n\nRandom sampling helps with external validity (generalizability), while random assignment helps with internal validity (causal inference). In many experiments, we don't have a random sample from the population, but we still randomize treatment assignment within our convenience sample.\n\n### Graphical Unit Overview\n\n\n\n```{mermaid}\nflowchart TD\n    %% Top nodes - conditions\n    A[\"Non-zero probability condition\"]:::gold\n    B[\"Individualism condition\"]:::gold\n    C[\"Unconfoundedness condition\"]:::gold\n    \n    %% Middle node - mechanisms\n    subgraph D[Classical Random Assignment Mechanisms]\n        F[\"Bernoulli Trial\"]:::carolinaBlue\n        G[\"Complete Randomized\\nExperiment (CRE)\"]:::carolinaBlue\n        H[\"Stratified Randomization\"]:::carolinaBlue\n        I[\"Rerandomization\"]:::carolinaBlue\n        J[\"Matched Pairs\"]:::carolinaBlue\n    end\n    subgraph E[Complex Experimental Designs]\n        K[\"Blocking\"]:::carolinaBlue\n        L[\"Covariate-adaptive Randomization\"]:::carolinaBlue\n        M[\"Minimization\"]:::carolinaBlue\n    end\n    \n    %% Bottom node - inference\n    N{{\"Design-conscious Inference\"}}:::uncGreen\n    \n    %% Connections\n    A --> D\n    B --> D\n    C --> D\n    A --> E\n    B --> E\n    C --> E\n    D --> N\n    E --> N\n\n    %% UNC Brand Colors\n    classDef gold fill:#FFD100,stroke:#13294B,stroke-width:1px,color:#13294B\n    classDef lightGrey fill:#F7F7F7,stroke:#13294B,stroke-width:1px,color:#13294B\n    classDef carolinaBlue fill:#4B9CD3,stroke:#13294B,stroke-width:1px,color:#FFFFFF\n    classDef uncGreen fill:#8DB434,stroke:#13294B,stroke-width:1px,color:#13294B\n    \n    %% Apply lightGrey style to subgraphs\n    style D fill:#F7F7F7,stroke:#13294B,stroke-width:1px,color:#13294B\n    style E fill:#F7F7F7,stroke:#13294B,stroke-width:1px,color:#13294B\n```\n\n\n\n### Classical Assignment Mechanisms\n\nThere are five primary approaches to random assignment, each with distinct advantages and disadvantages:\n\n1.  Bernoulli trials\n2.  Complete randomization\n3.  Re-randomization\n4.  Stratified randomization\n5.  Matched-pair designs\n\nLet's examine each approach in detail.\n\n## Bernoulli Trials\n\nBernoulli trials represent the simplest approach to randomization, where each unit is assigned to treatment independently with a fixed probability. This is conceptually equivalent to flipping a coin for each participant, with heads resulting in treatment assignment and tails resulting in control assignment.\n\n### Implementation\n\nLet's first create a dataset to work with:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\n\n# Generate data with 1000 participants\nn <- 1000\n\n# Create baseline covariates\ndt <- data.table(\n  # ID variable\n  id = 1:n,\n  \n  # Covariates that will be used for stratification\n  age = sample(18:80, n, replace = TRUE),                   # Continuous \n  education = sample(c(\"None\", \"Primary\", \"Secondary\", \"Higher\"), n, replace = TRUE, \n                    prob = c(0.1, 0.3, 0.4, 0.2)),          # Categorical\n  \n  # Additional covariates not used for stratification\n  female = rbinom(n, 1, 0.55),                              # Binary\n  income = round(rlnorm(n, meanlog = 10, sdlog = 1), 2),    # Continuous, right-skewed\n  rural = rbinom(n, 1, 0.4),                                # Binary\n  chronic_disease = rbinom(n, 1, 0.3),                      # Binary\n  satisfaction = sample(1:5, n, replace = TRUE,             # Ordinal 1-5 scale\n                       prob = c(0.1, 0.2, 0.4, 0.2, 0.1))\n)\n\n# Convert categorical variables to factors for clearer output\ndt[, education := factor(education, levels = c(\"None\", \"Primary\", \"Secondary\", \"Higher\"))]\n\n# View data structure\nprint(\"Data structure:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Data structure:\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(dt)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nClasses 'data.table' and 'data.frame':\t1000 obs. of  8 variables:\n $ id             : int  1 2 3 4 5 6 7 8 9 10 ...\n $ age            : int  19 34 62 45 44 74 40 24 36 34 ...\n $ education      : Factor w/ 4 levels \"None\",\"Primary\",..: 3 3 3 2 4 3 3 2 3 3 ...\n $ female         : int  1 1 1 0 1 1 1 1 1 1 ...\n $ income         : num  15382 38850 10788 42119 17465 ...\n $ rural          : int  0 1 0 0 0 1 1 0 1 1 ...\n $ chronic_disease: int  1 0 1 1 1 0 0 0 0 0 ...\n $ satisfaction   : int  2 3 1 2 1 5 3 1 3 3 ...\n - attr(*, \".internal.selfref\")=<externalptr> \n```\n\n\n:::\n\n```{.r .cell-code}\n# View the first 10 observations\nhead(dt)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      id   age education female   income rural chronic_disease satisfaction\n   <int> <int>    <fctr>  <int>    <num> <int>           <int>        <int>\n1:     1    19 Secondary      1 15381.84     0               1            2\n2:     2    34 Secondary      1 38849.92     1               0            3\n3:     3    62 Secondary      1 10788.07     0               1            1\n4:     4    45   Primary      0 42118.52     0               1            2\n5:     5    44    Higher      1 17465.41     0               1            1\n6:     6    74 Secondary      1 18718.60     1               0            5\n```\n\n\n:::\n:::\n\n\n\nNow let's randomize using Bernoulli:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make a copy of the data (so we can compare to other randomization methods below)\ndt_bern <- copy(dt)\n\n# Bernoulli trial example\nset.seed(072111)\n\np <- 0.5  # Probability of treatment assignment\n\n# Independent random assignment\ndt_bern[, treatment := rbinom(.N, 1, p)]\n\n# Check resulting allocation\ndt_bern[, .N, by = treatment]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   treatment     N\n       <int> <int>\n1:         0   514\n2:         1   486\n```\n\n\n:::\n:::\n\n\n\n### Advantages and Disadvantages\n\n**Advantages:**\n\n-   Simple to implement\n-   Can randomize as participants arrive (no need to know full sample in advance)\n-   No baseline data needed\n\n**Disadvantages:** - Random group sizes (can result in imbalanced treatment allocation) - Potential imbalance on key covariates - Vulnerable to implementation problems\n\n### Case Study: The Canadian National Breast Screening Study\n\nThe Canadian National Breast Screening Study (CNBSS) provides a cautionary tale about vulnerabilities in Bernoulli-type randomization. This major randomized trial evaluated the effectiveness of mammography screening for breast cancer in the 1980s.\n\nThe study used a variant of simple alternating assignment—assigning the first woman to treatment, the second to control, and so on. However, several critical flaws emerged:\n\n1.  **Pre-randomization examination**: Women received clinical breast exams before randomization, providing information that could influence assignment\n2.  **Knowledge of the assignment schedule**: Staff knew that assignments alternated, creating opportunities for manipulation\n3.  **Inadequate concealment**: Study coordinators could see which group the next woman would be assigned to\n4.  **Evidence of manipulation**: Later audits found names overwritten, identities reversed, and lines skipped in assignment ledgers\n\nThe consequences were severe: women with palpable lumps were disproportionately assigned to the mammography group, creating a significant selection bias. The mammography group had a 68% higher incidence of advanced cancers at baseline! This likely masked any potential benefits of screening, as the study ultimately reported no mortality benefit from mammography.\\[\\^1\\]\n\nThis case highlights how vulnerable simple randomization schemes can be to manipulation, especially when those implementing the study have preferences about treatment assignment or when the randomization process is transparent and predictable. Note that there is nothing wrong with Bernoulli trials, but you should carefully consider how to impelment randomization to preserve the integrity of the randomization process. Especially when working with partner organizations (which we do all the time in health services research), one needs to work with these partners to devise a randomization protocol that fits their existing workflow but protects the randomization process.\n\n## Complete Randomization\n\nComplete randomization addresses some of the limitations of Bernoulli trials by fixing the number of units assigned to each treatment condition, ensuring the desired allocation ratio is achieved exactly.\n\n### Implementation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Copy data\ndt_cr <- copy(dt)\n\nset.seed(072111)  # Set seed for reproducibility\n\n# Parameters\np <- 0.5          # Proportion to assign to treatment\n\n# Add a column with uniform random numbers from 0 to 1.\ndt_cr[, random_num := runif(.N, min = 0, max = 1)]\n\n# Sort by random number\nsetorder(dt_cr, random_num)\n\n# Assign first p% to treatment\ndt_cr[, treatment := 0]\ndt_cr[1:(.N*p), treatment := 1]\n\n# Check resulting allocation\ndt_cr[, .N, by = treatment]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   treatment     N\n       <num> <int>\n1:         1   500\n2:         0   500\n```\n\n\n:::\n:::\n\n\n\nIn complete randomization, we first determine exactly how many units will receive each treatment. Then we generate a random ordering of all units and assign the first $N_p$ units to treatment and the remaining $N_0$ units to control.\n\n### Advantages and Disadvantages\n\n**Advantages:**\n\n-   Guarantees exactly the desired allocation ratio\n\n-   Avoids power loss from uneven group sizes - Still relatively simple to implement\n\n**Disadvantages:**\n\n-   Requires knowing the full sample in advance\n\n-   Still subject to chance imbalance on covariates\n\nLet's check the balance we got for the two examples above by running t-tests comparing the treatment and control groups.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# First let's create a function to perform t-tests and create a formatted results table\nrun_ttests <- function(dt, title) {\n  results <- data.table(\n    variable = character(),\n    method = character(),\n    mean_control = numeric(),\n    mean_treated = numeric(),\n    diff = numeric(),\n    p_value = numeric(),\n    significant = character()\n  )\n  \n  for (var in baseline_vars) {\n    # For categorical variables (factor), we need to handle differently\n    if (is.factor(dt[[var]])) {\n      # For each level of the factor\n      for (level in levels(dt[[var]])) {\n        # Create temporary binary indicator\n        dt[, temp := as.numeric(get(var) == level)]\n        \n        # Calculate means\n        mean_control <- dt[treatment == 0, mean(temp)]\n        mean_treated <- dt[treatment == 1, mean(temp)]\n        \n        # Run t-test\n        t_result <- t.test(dt[treatment == 1, temp], \n                           dt[treatment == 0, temp])\n        \n        # Add to results\n        results <- rbind(results, data.table(\n          variable = paste0(var, \": \", level),\n          method = title,\n          mean_control = mean_control,\n          mean_treated = mean_treated,\n          diff = mean_treated - mean_control,\n          p_value = t_result$p.value,\n          significant = ifelse(t_result$p.value < 0.05, \"*\", \"\")\n        ))\n        \n        # Remove temporary variable\n        dt[, temp := NULL]\n      }\n    } else {\n      # For continuous and binary variables\n      mean_control <- dt[treatment == 0, mean(get(var), na.rm = TRUE)]\n      mean_treated <- dt[treatment == 1, mean(get(var), na.rm = TRUE)]\n      \n      # Run t-test\n      t_result <- t.test(\n        dt[treatment == 1, get(var)], \n        dt[treatment == 0, get(var)]\n      )\n      \n      # Add to results\n      results <- rbind(results, data.table(\n        variable = var,\n        method = title,\n        mean_control = mean_control,\n        mean_treated = mean_treated,\n        diff = mean_treated - mean_control,\n        p_value = t_result$p.value,\n        significant = ifelse(t_result$p.value < 0.05, \"*\", \"\")\n      ))\n    }\n  }\n  \n  return(results)\n}\n\n# Now let's run the tests\n\n## List of all baseline covariates to test\nbaseline_vars <- c(\"age\", \"education\", \"female\", \"income\", \"rural\", \"chronic_disease\", \"satisfaction\")\n\n# Run t-tests\nttest_bern <- run_ttests(dt_bern, \"Bernoulli - t-test\")\nttest_cr <- run_ttests(dt_cr, \"Complete - t-test\")\n\nprint(ttest_bern)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                variable             method mean_control mean_treated\n                  <char>             <char>        <num>        <num>\n 1:                  age Bernoulli - t-test 5.029767e+01 4.860905e+01\n 2:      education: None Bernoulli - t-test 1.050584e-01 1.172840e-01\n 3:   education: Primary Bernoulli - t-test 3.112840e-01 3.209877e-01\n 4: education: Secondary Bernoulli - t-test 3.735409e-01 3.971193e-01\n 5:    education: Higher Bernoulli - t-test 2.101167e-01 1.646091e-01\n 6:               female Bernoulli - t-test 5.972763e-01 5.802469e-01\n 7:               income Bernoulli - t-test 3.698802e+04 3.183656e+04\n 8:                rural Bernoulli - t-test 3.988327e-01 4.074074e-01\n 9:      chronic_disease Bernoulli - t-test 3.171206e-01 3.086420e-01\n10:         satisfaction Bernoulli - t-test 2.964981e+00 2.917695e+00\n             diff    p_value significant\n            <num>      <num>      <char>\n 1: -1.688612e+00 0.14555945            \n 2:  1.222558e-02 0.53949726            \n 3:  9.703608e-03 0.74185085            \n 4:  2.357849e-02 0.44441213            \n 5: -4.550768e-02 0.06504122            \n 6: -1.702935e-02 0.58485993            \n 7: -5.151461e+03 0.06919766            \n 8:  8.574723e-03 0.78260046            \n 9: -8.478647e-03 0.77281943            \n10: -4.728507e-02 0.50045109            \n```\n\n\n:::\n\n```{.r .cell-code}\nprint(ttest_cr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                variable            method mean_control mean_treated     diff\n                  <char>            <char>        <num>        <num>    <num>\n 1:                  age Complete - t-test       48.630       50.324    1.694\n 2:      education: None Complete - t-test        0.116        0.106   -0.010\n 3:   education: Primary Complete - t-test        0.320        0.312   -0.008\n 4: education: Secondary Complete - t-test        0.396        0.374   -0.022\n 5:    education: Higher Complete - t-test        0.168        0.208    0.040\n 6:               female Complete - t-test        0.584        0.594    0.010\n 7:               income Complete - t-test    31828.744    37140.081 5311.337\n 8:                rural Complete - t-test        0.404        0.402   -0.002\n 9:      chronic_disease Complete - t-test        0.316        0.310   -0.006\n10:         satisfaction Complete - t-test        2.914        2.970    0.056\n       p_value significant\n         <num>      <char>\n 1: 0.14434344            \n 2: 0.61514873            \n 3: 0.78582226            \n 4: 0.47518803            \n 5: 0.10571624            \n 6: 0.74823610            \n 7: 0.06446256            \n 8: 0.94865983            \n 9: 0.83809577            \n10: 0.42490327            \n```\n\n\n:::\n:::\n\n\n\n### Chance Imbalance in Complete Randomization\n\nEven with perfect implementation of complete randomization, covariates may still be imbalanced by chance. In a simulation study using data from the National Longitudinal Survey of Youth (NLSY) with 722 subjects:\\[\\^1\\]\n\n-   \\~45% of randomizations had all covariates balanced\n-   \\~30% had one imbalanced covariate\n-   The remaining had multiple imbalanced covariates\n\nThis raises two critical questions: 1. How can we ensure better balance in the design phase? 2. What should we do if imbalance occurs after randomization?\n\n**Our next three approaches address the first question by improving balance through more sophisticated randomization techniques.**\n\n## Re-randomization\n\nRe-randomization attempts to improve covariate balance by generating multiple possible randomizations and selecting one with good balance.\n\nThere are two common approaches to re-randomization:\n\n1.  **Threshold approach**: Generate randomizations until all p-values for covariate balance exceed a threshold (e.g., p \\> 0.1)\n2.  **Optimization approach**: Generate a large number of randomizations (e.g., 1,000) and select the one with the best overall balance\n\n### Threshold Approach\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Copy the data again\ndt_rerand_threshold <- copy(dt)\n\n# Re-randomization - Threshold Approach:\n# Function to test balance on key covariates\ntest_balance <- function(dt) {\n  # Define key covariates to check balance on\n  balance_vars <- c(\"age\", \"education\", \"female\", \"income\", \"rural\", \"chronic_disease\", \"satisfaction\")\n  \n  # Store p-values\n  p_values <- numeric(length(balance_vars))\n  names(p_values) <- balance_vars\n  \n  for (i in seq_along(balance_vars)) {\n    var <- balance_vars[i]\n    \n    # For categorical variables\n    if (is.factor(dt[[var]])) {\n      # Create model matrix (one-hot encoding)\n      formula_str <- paste0(\"~ \", var, \" - 1\")\n      mm <- model.matrix(as.formula(formula_str), data = dt)\n      # Test each level except the reference\n      p_vals_cat <- numeric(ncol(mm))\n      for (j in 1:ncol(mm)) {\n        t_result <- t.test(mm[dt$treatment == 1, j], mm[dt$treatment == 0, j])\n        p_vals_cat[j] <- t_result$p.value\n      }\n      # Use minimum p-value (most imbalanced category)\n      p_values[i] <- min(p_vals_cat)\n    } else {\n      # For continuous or binary variables\n      t_result <- t.test(dt[treatment == 1, get(var)], dt[treatment == 0, get(var)])\n      p_values[i] <- t_result$p.value\n    }\n  }\n  \n  return(p_values)\n}\n\n# Re-randomization with threshold approach\n# Continue generating randomizations until all p-values > 0.10\nmax_attempts <- 1000  # Safety limit to prevent infinite loops\nattempt <- 0\nbalanced <- FALSE\n\ncat(\"\\nPerforming re-randomization with threshold approach...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nPerforming re-randomization with threshold approach...\n```\n\n\n:::\n\n```{.r .cell-code}\nwhile (!balanced && attempt < max_attempts) {\n  attempt <- attempt + 1\n  \n  # Generate a new randomization\n  dt_rerand_threshold[, treatment := rbinom(.N, 1, 0.5)]\n  \n  # Test balance\n  p_values <- test_balance(dt_rerand_threshold)\n  \n  # Check if all p-values are above threshold (0.10)\n  if (all(p_values > 0.10)) {\n    balanced <- TRUE\n    cat(\"Found balanced randomization after\", attempt, \"attempts\\n\")\n    cat(\"Balance p-values:\", paste(names(p_values), round(p_values, 4), collapse=\", \"), \"\\n\\n\")\n  } else if (attempt %% 100 == 0) {\n    cat(\"Completed\", attempt, \"attempts, continuing search...\\n\")\n  }\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFound balanced randomization after 1 attempts\nBalance p-values: age 0.3607, education 0.1213, female 0.6851, income 0.595, rural 0.6301, chronic_disease 0.3026, satisfaction 0.1012 \n```\n\n\n:::\n\n```{.r .cell-code}\nif (!balanced) {\n  cat(\"Warning: Could not find perfectly balanced randomization after\", max_attempts, \"attempts\\n\")\n  cat(\"Using best randomization found so far\\n\\n\")\n}\n```\n:::\n\n\n\n### Optimization approach\n\nYou can define the \"best\" overall balance in different ways. Here we'll use the Mahalanobis distance.\n\n::: callout-note\nThe Mahalanobis distance is a statistical measure that quantifies the distance between a point and a distribution in multivariate space. The Mahalanobis distance is formally defined as:\n\n$$\nd_{maha} = \\sqrt{(x_B - X_A)^TC^{-1}(x_B - x_A)}\n$$\n\nWhere: • $x_A$ and $x_B$ are a pair of objects • $C$ is the sample covariance matrix • $C^{-1}$ is the inverse of the covariance matrix • $T$ denotes the transpose operation\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Copy data\n\ndt_rerand_optimal <- copy(dt)\n\n# Re-randomization - Optimization Approach:\n# Generate multiple randomizations and select the one with best overall balance\n\ncat(\"Performing re-randomization with optimization approach...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPerforming re-randomization with optimization approach...\n```\n\n\n:::\n\n```{.r .cell-code}\nn_candidates <- 1000\nmahalanobis_distances <- numeric(n_candidates)\n\n# Generate covariates matrix (need to handle factors separately)\ncat(\"Converting covariates to numeric for Mahalanobis distance calculation...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConverting covariates to numeric for Mahalanobis distance calculation...\n```\n\n\n:::\n\n```{.r .cell-code}\ncov_vars <- c(\"age\", \"female\", \"income\", \"rural\", \"chronic_disease\", \"satisfaction\")\n\n# Add dummy variables for education\nedu_dummies <- model.matrix(~ education - 1, data = dt_rerand_optimal)\nX <- cbind(\n  as.matrix(dt_rerand_optimal[, ..cov_vars]),\n  edu_dummies\n)\n\n# Calculate covariance matrix of covariates\nS <- cov(X)\nS_inv <- tryCatch({\n  solve(S)  # Try to compute inverse\n}, error = function(e) {\n  cat(\"Covariance matrix is singular, using pseudoinverse...\\n\")\n  # Use pseudoinverse if matrix is singular\n  library(MASS)\n  ginv(S)\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCovariance matrix is singular, using pseudoinverse...\n```\n\n\n:::\n\n```{.r .cell-code}\n# Generate candidate randomizations and calculate balance measure\nfor (i in 1:n_candidates) {\n  # Generate a new randomization\n  treatment_assign <- rbinom(n, 1, 0.5)\n  \n  # Calculate difference in means\n  mean_diff <- colMeans(X[treatment_assign == 1, ]) - colMeans(X[treatment_assign == 0, ])\n  \n  # Calculate Mahalanobis distance\n  mahalanobis_distances[i] <- t(mean_diff) %*% S_inv %*% mean_diff\n  \n  if (i %% 200 == 0) cat(\"Generated\", i, \"candidate randomizations...\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGenerated 200 candidate randomizations...\nGenerated 400 candidate randomizations...\nGenerated 600 candidate randomizations...\nGenerated 800 candidate randomizations...\nGenerated 1000 candidate randomizations...\n```\n\n\n:::\n\n```{.r .cell-code}\n# Find the randomization with smallest Mahalanobis distance\nbest_idx <- which.min(mahalanobis_distances)\ncat(\"Selected optimal randomization (candidate\", best_idx, \"with Mahalanobis distance =\", \n    round(mahalanobis_distances[best_idx], 4), \")\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSelected optimal randomization (candidate 165 with Mahalanobis distance = 0 )\n```\n\n\n:::\n\n```{.r .cell-code}\n# Generate the best randomization\nset.seed(best_idx)  # For reproducibility\ndt_rerand_optimal[, treatment := rbinom(.N, 1, 0.5)]\n```\n:::\n\n\n\n### Drawbacks of Re-randomization\n\nWhile re-randomization can improve balance, it has several limitations:\n\n-   **Opaque constraints**: The process creates a \"black box\" where it's unclear what constraints are being imposed\n-   **Unusual handling of outliers**: Extreme values may force unusual allocation patterns\n-   **Computational cost**: May require many iterations, especially with multiple covariates\n-   **Potential futility**: If criteria are too strict, acceptable randomizations may be extremely rare\n-   **Statistical inference complications**: Standard methods don't account for the re-randomization process\n-   **Limited scope**: Still cannot balance on unobserved covariates\n\n## Stratified (Block) Randomization\n\nStratified randomization (also called block randomization) directly addresses the balance issue by dividing the sample into strata based on covariates and randomizing separately within each stratum.\n\nIn this approach, we first create strata based on combinations of important covariates, then randomize separately within each stratum. This guarantees perfect balance on the stratification variables.\n\n### Selecting Stratification Variables\n\nNot all covariates are equally important for stratification. Consider these guidelines:\n\n-   **Discrete variables** are easier to implement than continuous ones\n-   Prioritize variables that **strongly predict outcomes** (baseline values of the outcome variable are especially important)\n-   Include variables where **heterogeneous effects** are expected (facilitates subgroup analysis)\n-   Be careful about creating **too many strata**, which can lead to \"small cell\" problems\n\n### Handling \"Misfits\"\n\nA practical challenge in stratified randomization occurs when strata sizes are not divisible by the number of treatment conditions (e.g., three people in a stratum with two treatment conditions). Options for these \"misfits\" include:\n\n-   Remove units randomly to create divisible strata\n-   Create a separate stratum for misfits\n-   Use a different randomization approach for misfits\n\n### Implementation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Copy the Data\ndt_strat <- copy(dt)\n\n# Set the seed using Zoe's bday\nset.seed(072111)  # For reproducibility\n\n# Convert categorical variables to factors for clearer output\ndt_strat[, education := factor(education, levels = c(\"None\", \"Primary\", \"Secondary\", \"Higher\"))]\n\n# Create age quintiles\ndt_strat[, age_quintile := cut(age, \n                         breaks = quantile(age, probs = seq(0, 1, 0.2), na.rm = TRUE), \n                         labels = 1:5, \n                         include.lowest = TRUE)]\n\n# View data structure\nprint(\"Data structure:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Data structure:\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(dt_strat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nClasses 'data.table' and 'data.frame':\t1000 obs. of  9 variables:\n $ id             : int  1 2 3 4 5 6 7 8 9 10 ...\n $ age            : int  19 34 62 45 44 74 40 24 36 34 ...\n $ education      : Factor w/ 4 levels \"None\",\"Primary\",..: 3 3 3 2 4 3 3 2 3 3 ...\n $ female         : int  1 1 1 0 1 1 1 1 1 1 ...\n $ income         : num  15382 38850 10788 42119 17465 ...\n $ rural          : int  0 1 0 0 0 1 1 0 1 1 ...\n $ chronic_disease: int  1 0 1 1 1 0 0 0 0 0 ...\n $ satisfaction   : int  2 3 1 2 1 5 3 1 3 3 ...\n $ age_quintile   : Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 1 2 4 3 3 5 2 1 2 2 ...\n - attr(*, \".internal.selfref\")=<externalptr> \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create strata ID by combining education and age quintile\ndt_strat[, strata := .GRP, by = .(education, age_quintile)]\n\n# Print strata information\nprint(\"Strata information:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Strata information:\"\n```\n\n\n:::\n\n```{.r .cell-code}\ndt_strat[, .(count = .N), by = .(education, age_quintile, strata)][order(strata)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    education age_quintile strata count\n       <fctr>       <fctr>  <int> <int>\n 1: Secondary            1      1    86\n 2: Secondary            2      2    75\n 3: Secondary            4      3    71\n 4:   Primary            3      4    60\n 5:    Higher            3      5    42\n 6: Secondary            5      6    76\n 7:   Primary            1      7    66\n 8:   Primary            4      8    69\n 9:   Primary            5      9    65\n10:   Primary            2     10    56\n11:      None            5     11    21\n12:    Higher            4     12    36\n13:    Higher            1     13    42\n14:    Higher            2     14    38\n15:    Higher            5     15    30\n16:      None            2     16    29\n17: Secondary            3     17    77\n18:      None            3     18    17\n19:      None            4     19    24\n20:      None            1     20    20\n    education age_quintile strata count\n```\n\n\n:::\n:::\n\n\n\nNow let's randomize half of the observations in each strata to treatment and half to control. To ensure 50/50 split, we'll use the Complete Randomization method within each strata:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt_strat[, treatment := 0]  # Initialize all to control\nfor (s in unique(dt_strat$strata)) {\n  # Get all units in this stratum\n  stratum_units <- dt_strat[strata == s, id]\n  n_units <- length(stratum_units)\n  \n  # Determine number to treat (half, rounded down)\n  n_treat <- floor(n_units/2)\n  \n  # Misfits: If n_units is odd, flip a coin to decide whether to round up or down\n  if (n_units %% 2 == 1) {\n    if (runif(1) < 0.5) n_treat <- n_treat + 1\n  }\n  \n  # Randomly select units for treatment\n  treated_units <- sample(stratum_units, n_treat)\n  \n  # Assign treatment\n  dt_strat[id %in% treated_units, treatment := 1]\n}\n\n# Print treatment assignment by strata for stratified randomization\nprint(\"Treatment assignment by strata in stratified randomization:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Treatment assignment by strata in stratified randomization:\"\n```\n\n\n:::\n\n```{.r .cell-code}\ndt_strat[, .(N = .N, \n             n_treated = sum(treatment), \n             pct_treated = mean(treatment)*100), \n         by = strata][order(strata)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    strata     N n_treated pct_treated\n     <int> <int>     <num>       <num>\n 1:      1    86        43    50.00000\n 2:      2    75        38    50.66667\n 3:      3    71        36    50.70423\n 4:      4    60        30    50.00000\n 5:      5    42        21    50.00000\n 6:      6    76        38    50.00000\n 7:      7    66        33    50.00000\n 8:      8    69        34    49.27536\n 9:      9    65        33    50.76923\n10:     10    56        28    50.00000\n11:     11    21        11    52.38095\n12:     12    36        18    50.00000\n13:     13    42        21    50.00000\n14:     14    38        19    50.00000\n15:     15    30        15    50.00000\n16:     16    29        14    48.27586\n17:     17    77        39    50.64935\n18:     18    17         9    52.94118\n19:     19    24        12    50.00000\n20:     20    20        10    50.00000\n    strata     N n_treated pct_treated\n```\n\n\n:::\n:::\n\n\n\n## Matched Pairs Randomization\n\nMatched pairs randomization represents the extreme case of stratification, where each stratum contains exactly two similar units, and one is randomly assigned to treatment and one to control.\n\nIn this approach, we first create pairs of similar units based on a distance metric, then randomly assign one member of each pair to treatment and the other to control. This guarantees excellent balance on the matching variables.\n\n## Implementation\n\n::: {callout-warning}\nIn this example, we're using what is referred to as a \"greedy\" matching algorithm. It is \"greedy\" because it makes locally optimal choices at each step without reconsidering earlier decisions, potentially missing the globally optimal solution. We're using this for now because it is clear and simple to impelment.\n\nIn practice, \"canned\" matching commands are commonly used to form matches and these often use other optimal matching algorithms. A non-greedy, optimal matching algorithm would consider all possible ways to pair units and select the configuration that minimizes the total sum of distances across all pairs. This is computationally more intensive (often solved using network optimization methods like the Hungarian algorithm) but guarantees the global minimum total distance.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt_matched <- copy(dt)\n\n# Set the seed using Zoe's bday\nset.seed(072111)  # For reproducibility\n\n# 1. Prepare data for matching\ncat(\"\\nPerforming matched randomization using Mahalanobis distance...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nPerforming matched randomization using Mahalanobis distance...\n```\n\n\n:::\n\n```{.r .cell-code}\n# Create matrix of variables to match on\nmatch_vars <- c(\"age\", \"female\", \"income\", \"rural\", \"chronic_disease\")\n\n# Convert education to dummy variables for inclusion in distance calculation\nedu_dummies <- model.matrix(~ education - 1, data = dt_matched)\ncolnames(edu_dummies) <- paste0(\"edu_\", levels(dt_matched$education))\n\n# Combine numeric variables with education dummies\nX <- cbind(as.matrix(dt_matched[, ..match_vars]), edu_dummies)\n\n# Calculate covariance matrix and inverse\nS <- cov(X)\nS_inv <- tryCatch({\n  solve(S)  # Try to compute inverse\n}, error = function(e) {\n  cat(\"Covariance matrix is singular, using pseudoinverse...\\n\")\n  # Use pseudoinverse if matrix is singular\n  library(MASS)\n  ginv(S)\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCovariance matrix is singular, using pseudoinverse...\n```\n\n\n:::\n\n```{.r .cell-code}\n# 2. Calculate pairwise Mahalanobis distances between all units\nn <- nrow(dt_matched)\ndist_matrix <- matrix(0, n, n)\n\n# Store original IDs to maintain correct mapping\noriginal_ids <- dt_matched$id\n\ncat(\"Calculating Mahalanobis distances between all units...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCalculating Mahalanobis distances between all units...\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (i in 1:(n-1)) {\n  for (j in (i+1):n) {\n    # Calculate vector of differences between units i and j\n    diff <- X[i,] - X[j,]\n    \n    # Calculate Mahalanobis distance\n    dist_matrix[i,j] <- dist_matrix[j,i] <- sqrt(t(diff) %*% S_inv %*% diff)\n  }\n  \n  if (i %% 100 == 0) cat(\"Processed\", i, \"of\", n, \"units...\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nProcessed 100 of 1000 units...\nProcessed 200 of 1000 units...\nProcessed 300 of 1000 units...\nProcessed 400 of 1000 units...\nProcessed 500 of 1000 units...\nProcessed 600 of 1000 units...\nProcessed 700 of 1000 units...\nProcessed 800 of 1000 units...\nProcessed 900 of 1000 units...\n```\n\n\n:::\n\n```{.r .cell-code}\n# 3. Create optimal pairs using greedy algorithm\ncat(\"Creating optimal pairs...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCreating optimal pairs...\n```\n\n\n:::\n\n```{.r .cell-code}\nunpaired_idx <- 1:n  # These are indices, not IDs\npairs_idx <- list()  # Store pairs of indices\n\nwhile (length(unpaired_idx) >= 2) {\n  # Find the nearest neighbor for the first unpaired unit\n  current_idx <- unpaired_idx[1]\n  distances <- dist_matrix[current_idx, unpaired_idx[-1]]\n  nearest_pos <- which.min(distances)\n  nearest_idx <- unpaired_idx[nearest_pos + 1]  # +1 because we excluded current from unpaired\n  \n  # Create a new pair of indices\n  pairs_idx <- c(pairs_idx, list(c(current_idx, nearest_idx)))\n  \n  # Remove these indices from unpaired\n  unpaired_idx <- unpaired_idx[!unpaired_idx %in% c(current_idx, nearest_idx)]\n  \n  if (length(pairs_idx) %% 50 == 0) cat(\"Created\", length(pairs_idx), \"pairs...\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCreated 50 pairs...\nCreated 100 pairs...\nCreated 150 pairs...\nCreated 200 pairs...\nCreated 250 pairs...\nCreated 300 pairs...\nCreated 350 pairs...\nCreated 400 pairs...\nCreated 450 pairs...\nCreated 500 pairs...\n```\n\n\n:::\n\n```{.r .cell-code}\n# Handle leftover unit if odd number of units\nif (length(unpaired_idx) == 1) {\n  cat(\"Note: Odd number of units. Unit index\", unpaired_idx, \"will be randomly assigned.\\n\")\n  # This unit will be handled separately\n}\n\n# 4. Convert index pairs to ID pairs and assign treatments\npairs <- lapply(pairs_idx, function(p) original_ids[p])\n\n# Reset pair_id and treatment in the dataset\ndt_matched[, pair_id := NA_integer_]\ndt_matched[, treatment := 0]  # Initialize all to control\n\ncat(\"Assigning pair IDs and treatment...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAssigning pair IDs and treatment...\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (i in seq_along(pairs)) {\n  # Assign pair ID to both units in the pair\n  dt_matched[id %in% pairs[[i]], pair_id := i]\n  \n  # Randomly select one unit for treatment\n  treated_id <- sample(pairs[[i]], 1)\n  dt_matched[id == treated_id, treatment := 1]\n}\n\n# Handle leftover unit if exists\nif (length(unpaired_idx) == 1) {\n  leftover_id <- original_ids[unpaired_idx]\n  \n  # Assign to a special \"pair\" ID\n  dt_matched[id == leftover_id, pair_id := length(pairs) + 1]\n  \n  # Randomly assign to treatment or control\n  if (runif(1) < 0.5) {\n    dt_matched[id == leftover_id, treatment := 1]\n  }\n}\n\n# Verify pair assignments\npair_counts <- dt_matched[!is.na(pair_id), .N, by = pair_id]\ncat(\"\\nVerifying pair assignments:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nVerifying pair assignments:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Number of unique pairs:\", nrow(pair_counts), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNumber of unique pairs: 500 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Distribution of pair sizes:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDistribution of pair sizes:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(table(pair_counts$N))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  2 \n500 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Check treatment balance\ncat(\"\\nTreatment balance:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTreatment balance:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Treatment group size:\", dt_matched[treatment == 1, .N], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTreatment group size: 500 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Control group size:\", dt_matched[treatment == 0, .N], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nControl group size: 500 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Display the first 10 pairs, sorted by pair_id\ndt_matched[pair_id %in% 1:10][order(pair_id), .(id, pair_id, treatment, age, education, income)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       id pair_id treatment   age education   income\n    <int>   <int>     <num> <int>    <fctr>    <num>\n 1:     1       1         1    19 Secondary 15381.84\n 2:   314       1         0    19      None 15029.52\n 3:     2       2         1    34 Secondary 38849.92\n 4:   377       2         0    33   Primary 35934.18\n 5:     3       3         0    62 Secondary 10788.07\n 6:   241       3         1    62 Secondary  9877.48\n 7:     4       4         0    45   Primary 42118.52\n 8:   449       4         1    45 Secondary 40293.28\n 9:     5       5         1    44    Higher 17465.41\n10:   846       5         0    44   Primary 17352.46\n11:     6       6         0    74 Secondary 18718.60\n12:   760       6         1    74 Secondary 18864.18\n13:     7       7         0    40 Secondary 13593.29\n14:   308       7         1    40 Secondary 15251.64\n15:     8       8         1    24   Primary 21565.13\n16:   468       8         0    24   Primary 22107.18\n17:     9       9         1    36 Secondary 22274.83\n18:   660       9         0    36    Higher 23510.64\n19:    10      10         1    34 Secondary  9627.04\n20:   490      10         0    34    Higher  9721.55\n       id pair_id treatment   age education   income\n```\n\n\n:::\n:::\n\n\n\n### Advantages and Limitations\n\n**Advantages:** - Achieves excellent balance on matching variables - Works well with continuous covariates - Reduces variance in treatment effect estimates\n\n**Limitations:** - Finding good matches becomes difficult with many covariates - May discard units that can't be well-matched - Requires all baseline data before randomization - Analysis must account for pairing structure\n\n## Verifying Balance: Approaches and Best Practices\n\nAfter randomization, it's crucial to verify that balance between the treatment and control group was achieved. Several approaches exist:\n\n-   Individual Covariate Tests: Test balance one-by-one\n-   Joint Omnibus Test: Test that all covariates are jointly balanced (often combined with tests on each covariate)\n-   Regression-Based Tests: Regress treatment assignment on each covariate. Also allows you to control for strata or matched pair fixed effects.\n\n### Individual Covariate Tests\n\nThe most common approach is to test each covariate separately: - t-tests for continuous variables - Chi-square tests for categorical variables\n\nLet's demonstrate this with data from the strata randomization example.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# List of all baseline covariates to test\nbaseline_vars <- c(\"age\", \"education\", \"female\", \"income\", \"rural\", \"chronic_disease\", \"satisfaction\")\n\n# Function to perform t-tests and create a formatted results table\nrun_ttests <- function(dt, title) {\n  results <- data.table(\n    variable = character(),\n    method = character(),\n    mean_control = numeric(),\n    mean_treated = numeric(),\n    diff = numeric(),\n    p_value = numeric(),\n    significant = character()\n  )\n  \n  for (var in baseline_vars) {\n    # For categorical variables (factor), we need to handle differently\n    if (is.factor(dt[[var]])) {\n      # For each level of the factor\n      for (level in levels(dt[[var]])) {\n        # Create temporary binary indicator\n        dt[, temp := as.numeric(get(var) == level)]\n        \n        # Calculate means\n        mean_control <- dt[treatment == 0, mean(temp)]\n        mean_treated <- dt[treatment == 1, mean(temp)]\n        \n        # Run t-test\n        t_result <- t.test(dt[treatment == 1, temp], \n                           dt[treatment == 0, temp])\n        \n        # Add to results\n        results <- rbind(results, data.table(\n          variable = paste0(var, \": \", level),\n          method = title,\n          mean_control = mean_control,\n          mean_treated = mean_treated,\n          diff = mean_treated - mean_control,\n          p_value = t_result$p.value,\n          significant = ifelse(t_result$p.value < 0.05, \"*\", \"\")\n        ))\n        \n        # Remove temporary variable\n        dt[, temp := NULL]\n      }\n    } else {\n      # For continuous and binary variables\n      mean_control <- dt[treatment == 0, mean(get(var), na.rm = TRUE)]\n      mean_treated <- dt[treatment == 1, mean(get(var), na.rm = TRUE)]\n      \n      # Run t-test\n      t_result <- t.test(\n        dt[treatment == 1, get(var)], \n        dt[treatment == 0, get(var)]\n      )\n      \n      # Add to results\n      results <- rbind(results, data.table(\n        variable = var,\n        method = title,\n        mean_control = mean_control,\n        mean_treated = mean_treated,\n        diff = mean_treated - mean_control,\n        p_value = t_result$p.value,\n        significant = ifelse(t_result$p.value < 0.05, \"*\", \"\")\n      ))\n    }\n  }\n  \n  return(results)\n}\n\n# Run t-tests for all randomization methods\nttest_strat <- run_ttests(dt_strat, \"Stratified - t-test\")\n\n#Display Result\n```\n:::\n\n\n\n### Joint Omnibus Tests\n\nF-tests can test multiple covariates simultaneously, reducing the multiple testing problem.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to perform F-test\njoint_balance_test <- function(dt) {\n  # Regress treatment on covariates\n  model <- lm(treatment ~ age + income + female + education + chronic_disease, \n              data = dt)\n  \n  # Extract F-statistic and p-value for joint significance\n  f_test <- summary(model)$fstatistic\n  f_value <- f_test[1]\n  df1 <- f_test[2]\n  df2 <- f_test[3]\n  p_value <- pf(f_value, df1, df2, lower.tail = FALSE)\n  \n  result <- data.table(\n    f_value = f_value,\n    df1 = df1,\n    df2 = df2,\n    p_value = p_value\n  )\n  \n  return(result)\n}\n\n# Run joint test\njoint_test <- joint_balance_test(dt_strat)\ncat(\"Joint balance test (F-test):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nJoint balance test (F-test):\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"F(\", joint_test$df1, \",\", joint_test$df2, \") = \", \n    round(joint_test$f_value, 2), \", p = \", round(joint_test$p_value, 4), \"\\n\", sep=\"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nF(7,992) = 0.49, p = 0.841\n```\n\n\n:::\n:::\n\n\n\n### Regression-Based Tests\n\nRegress treatment assignment on each covariate; if randomization worked, coefficients should be insignificant.\n\nAgain, we'll use the data created for the stratified randomization example. First, let's look at this approach not controlling for strata fixed effects:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fixest) # For fixed effects\n\n# Function to perform OLS regressions without strata fixed effects\nrun_ols_no_strata <- function(dt, title) {\n  results <- data.table(\n    variable = character(),\n    method = character(),\n    coefficient = numeric(),\n    std_error = numeric(),\n    p_value = numeric(),\n    significant = character()\n  )\n  \n  for (var in baseline_vars) {\n    # Handle factor variables\n    if (is.factor(dt[[var]])) {\n      # Create one-hot encoding\n      for (level in levels(dt[[var]])[2:length(levels(dt[[var]]))]) {  # Skip first level (reference)\n        dt[, temp := as.numeric(get(var) == level)]\n        \n        # Run regression\n        reg <- feols(temp ~ treatment, data = dt)\n        \n        # Add to results\n        results <- rbind(results, data.table(\n          variable = paste0(var, \": \", level, \" vs \", levels(dt[[var]])[1]),\n          method = title,\n          coefficient = coef(reg)[\"treatment\"],\n          std_error = se(reg)[\"treatment\"],\n          p_value = pvalue(reg)[\"treatment\"],\n          significant = ifelse(pvalue(reg)[\"treatment\"] < 0.05, \"*\", \"\")\n        ))\n        \n        # Remove temporary variable\n        dt[, temp := NULL]\n      }\n    } else {\n      # For continuous and binary variables\n      formula_str <- paste0(var, \" ~ treatment\")\n      reg <- feols(as.formula(formula_str), data = dt)\n      \n      # Add to results\n      results <- rbind(results, data.table(\n        variable = var,\n        method = title,\n        coefficient = coef(reg)[\"treatment\"],\n        std_error = se(reg)[\"treatment\"],\n        p_value = pvalue(reg)[\"treatment\"],\n        significant = ifelse(pvalue(reg)[\"treatment\"] < 0.05, \"*\", \"\")\n      ))\n    }\n  }\n  \n  return(results)\n}\n\n# Run OLS without strata for both randomization methods\nols_strat <- run_ols_no_strata(dt_strat, \"Stratified  - OLS no Strata FE\")\n\n# Display results\nprint(ols_strat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                       variable                         method   coefficient\n                         <char>                         <char>         <num>\n1:                          age Stratified  - OLS no Strata FE  2.221876e-01\n2:   education: Primary vs None Stratified  - OLS no Strata FE -2.528040e-03\n3: education: Secondary vs None Stratified  - OLS no Strata FE  2.920047e-03\n4:    education: Higher vs None Stratified  - OLS no Strata FE -1.504024e-03\n5:                       female Stratified  - OLS no Strata FE -3.471256e-02\n6:                       income Stratified  - OLS no Strata FE  1.481540e+03\n7:                        rural Stratified  - OLS no Strata FE  1.477624e-02\n8:              chronic_disease Stratified  - OLS no Strata FE -4.050465e-02\n9:                 satisfaction Stratified  - OLS no Strata FE  4.446471e-02\n      std_error   p_value significant\n          <num>     <num>      <char>\n1: 1.160745e+00 0.8482370            \n2: 2.943325e-02 0.9315706            \n3: 3.080592e-02 0.9245019            \n4: 2.473571e-02 0.9515277            \n5: 3.112980e-02 0.2650800            \n6: 2.873209e+03 0.6062205            \n7: 3.104979e-02 0.6342580            \n8: 2.932947e-02 0.1675812            \n9: 7.016046e-02 0.5263844            \n```\n\n\n:::\n:::\n\n\n\nThese should be very close to the t-tests above.\n\nNow let's do this controlling for strata. The reason we'd want to do this is because, as we'll see later, we need to estimate the treatment effect following the way the randomization was done, period. In other words, these need to be aligned. So, if we want to test our balance on baseline covariates, estimate the treatment effect once we have the endline data, it makes sense to include strata fixed effects here.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to perform OLS regressions with strata fixed effects\nrun_ols_with_strata <- function(dt, title) {\n  results <- data.table(\n    variable = character(),\n    method = character(),\n    coefficient = numeric(),\n    std_error = numeric(),\n    p_value = numeric(),\n    significant = character()\n  )\n  \n  for (var in baseline_vars) {\n    # Handle factor variables\n    if (is.factor(dt[[var]])) {\n      for (level in levels(dt[[var]])[2:length(levels(dt[[var]]))]) {  # Skip first level (reference)\n        dt[, temp := as.numeric(get(var) == level)]\n        \n        # Run regression with strata fixed effects\n        reg <- feols(temp ~ treatment | strata, data = dt)\n        \n        # Add to results\n        results <- rbind(results, data.table(\n          variable = paste0(var, \": \", level, \" vs \", levels(dt[[var]])[1]),\n          method = title,\n          coefficient = coef(reg)[\"treatment\"],\n          std_error = se(reg)[\"treatment\"],\n          p_value = pvalue(reg)[\"treatment\"],\n          significant = ifelse(pvalue(reg)[\"treatment\"] < 0.05, \"*\", \"\")\n        ))\n        \n        # Remove temporary variable\n        dt[, temp := NULL]\n      }\n    } else {\n      # For continuous and binary variables\n      formula_str <- paste0(var, \" ~ treatment | strata\")\n      reg <- feols(as.formula(formula_str), data = dt)\n      \n      # Add to results\n      results <- rbind(results, data.table(\n        variable = var,\n        method = title,\n        coefficient = coef(reg)[\"treatment\"],\n        std_error = se(reg)[\"treatment\"],\n        p_value = pvalue(reg)[\"treatment\"],\n        significant = ifelse(pvalue(reg)[\"treatment\"] < 0.05, \"*\", \"\")\n      ))\n    }\n  }\n  \n  return(results)\n}\n\n# Run OLS with strata/pair fixed effects\nols_strat_fe <- run_ols_with_strata(dt_strat, \"Stratified - OLS with strata FE\")\n\n# Display results\nprint(ols_strat_fe)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                       variable                          method   coefficient\n                         <char>                          <char>         <num>\n1:                          age Stratified - OLS with strata FE    0.11773106\n2:   education: Primary vs None Stratified - OLS with strata FE    0.00000000\n3: education: Secondary vs None Stratified - OLS with strata FE    0.00000000\n4:    education: Higher vs None Stratified - OLS with strata FE    0.00000000\n5:                       female Stratified - OLS with strata FE   -0.03450692\n6:                       income Stratified - OLS with strata FE 1478.11717275\n7:                        rural Stratified - OLS with strata FE    0.01458971\n8:              chronic_disease Stratified - OLS with strata FE   -0.04085313\n9:                 satisfaction Stratified - OLS with strata FE    0.04348112\n      std_error   p_value significant\n          <num>     <num>      <char>\n1: 2.273435e-01 0.6105367            \n2:          NaN        NA        <NA>\n3:          NaN        NA        <NA>\n4:          NaN        NA        <NA>\n5: 2.982420e-02 0.2616078            \n6: 2.687661e+03 0.5887514            \n7: 2.894125e-02 0.6199764            \n8: 2.597797e-02 0.1323144            \n9: 8.089327e-02 0.5971538            \n```\n\n\n:::\n:::\n\n\n\n::: callout-note\nNotice the regressions for education variables are not computing. Why do you think this is?\n:::\n\n### Standardized Differences\n\nFor large samples, p-values become less informative as tiny imbalances become statistically significant. Standardized mean differences (SMDs) provide a sample size-independent measure:\n\n$$SMD = \\frac{\\bar{X}_{treatment} - \\bar{X}_{control}}{\\sqrt{\\frac{s^2_{treatment} + s^2_{control}}{2}}}$$\n\nA common rule of thumb is that an absolute SMD less than 0.1 indicates negligible imbalance.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate standardized differences \nstandardized_diff <- function(dt) {\n  covariates <- c(\"age\", \"income\", \"female\", \"chronic_disease\")\n  results <- data.table(\n    covariate = character(),\n    mean_treated = numeric(),\n    mean_control = numeric(),\n    sd_treated = numeric(),\n    sd_control = numeric(),\n    std_diff = numeric(),\n    stringsAsFactors = FALSE\n  )\n  \n  for (cov in covariates) {\n    # Calculate means and SDs by group\n    treated <- dt[treatment == 1, get(cov)]  # Use get() to retrieve column dynamically\n    control <- dt[treatment == 0, get(cov)]  # Use get() to retrieve column dynamically\n    \n    mean_treated <- mean(treated, na.rm = TRUE)\n    mean_control <- mean(control, na.rm = TRUE)\n    sd_treated <- sd(treated, na.rm = TRUE)\n    sd_control <- sd(control, na.rm = TRUE)\n    \n    # Calculate standardized difference\n    pooled_sd <- sqrt((sd_treated^2 + sd_control^2) / 2)\n    std_diff <- (mean_treated - mean_control) / pooled_sd\n    \n    results <- rbind(results, data.table(\n      covariate = cov,\n      mean_treated = mean_treated,\n      mean_control = mean_control,\n      sd_treated = sd_treated,\n      sd_control = sd_control,\n      std_diff = std_diff\n    ))\n  }\n  \n  # Handle education separately (categorical variable)\n  if (\"education\" %in% names(dt)) {\n    # For each level of education\n    edu_levels <- levels(dt$education)\n    for (level in edu_levels) {\n      # Create indicator for this level\n      dt[, temp := as.numeric(education == level)]\n      \n      # Calculate means by group\n      treated <- dt[treatment == 1, mean(temp, na.rm = TRUE)]\n      control <- dt[treatment == 0, mean(temp, na.rm = TRUE)]\n      \n      # For proportions, the SD is sqrt(p*(1-p))\n      sd_treated <- sqrt(treated * (1-treated))\n      sd_control <- sqrt(control * (1-control))\n      \n      # Calculate standardized difference\n      pooled_sd <- sqrt((sd_treated^2 + sd_control^2) / 2)\n      # Avoid division by zero\n      if (pooled_sd == 0) {\n        std_diff <- 0\n      } else {\n        std_diff <- (treated - control) / pooled_sd\n      }\n      \n      results <- rbind(results, data.table(\n        covariate = paste0(\"education: \", level),\n        mean_treated = treated,\n        mean_control = control,\n        sd_treated = sd_treated,\n        sd_control = sd_control,\n        std_diff = std_diff\n      ))\n      \n      # Remove temporary variable\n      dt[, temp := NULL]\n    }\n  }\n  \n  return(results)\n}\n\n# Calculate standardized differences\nstd_diffs <- standardized_diff(dt_strat)\nprint(std_diffs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              covariate mean_treated mean_control   sd_treated   sd_control\n                 <char>        <num>        <num>        <num>        <num>\n1:                  age 4.958765e+01 4.936546e+01 1.833769e+01 1.836811e+01\n2:               income 3.522222e+04 3.374068e+04 4.624246e+04 4.459409e+04\n3:               female 5.717131e-01 6.064257e-01 4.953241e-01 4.890335e-01\n4:      chronic_disease 2.928287e-01 3.333333e-01 4.555144e-01 4.718785e-01\n5:      education: None 1.115538e-01 1.104418e-01 3.148167e-01 3.134396e-01\n6:   education: Primary 3.147410e-01 3.172691e-01 4.644127e-01 4.654132e-01\n7: education: Secondary 3.864542e-01 3.835341e-01 4.869367e-01 4.862465e-01\n8:    education: Higher 1.872510e-01 1.887550e-01 3.901129e-01 3.913139e-01\n       std_diff\n          <num>\n1:  0.012106399\n2:  0.032614530\n3: -0.070526901\n4: -0.087338046\n5:  0.003540005\n6: -0.005437661\n7:  0.006001020\n8: -0.003849426\n```\n\n\n:::\n:::\n\n\n\n### Comprehensive \"Table 1\"\n\nNow, let's create a comprehensive \"Table 1\" for the stratified random sample\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Install and load required packages\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(gt)\n\n# Calculate standardized differences for stratified randomization\nstd_diff_strat <- standardized_diff(dt_strat)\n\n# Function to extract p-values from all balance tests\nextract_pvalues <- function(test_results) {\n  results <- test_results[, .(variable, p_value)]\n  setnames(results, \"variable\", \"covariate\")\n  return(results)\n}\n\n# Extract p-values from different testing approaches for stratified randomization\npvals_strat_ttest <- extract_pvalues(ttest_strat)\npvals_strat_ttest[, approach := \"t-test\"]\n\npvals_strat_ols <- extract_pvalues(ols_strat)\npvals_strat_ols[, approach := \"OLS (no strata FE)\"]\n\npvals_strat_ols_fe <- extract_pvalues(ols_strat_fe)\npvals_strat_ols_fe[, approach := \"OLS (with strata FE)\"]\n\n# Combine all p-values for stratified randomization\nstrat_pvals <- rbind(\n  pvals_strat_ttest,\n  pvals_strat_ols,\n  pvals_strat_ols_fe\n)\n\n# Create a wide format of p-values\npvals_wide <- strat_pvals %>%\n  as.data.frame() %>%\n  pivot_wider(\n    id_cols = covariate,\n    names_from = approach,\n    values_from = p_value\n  )\n\n# Join with standardized differences\nstrat_balance_table <- merge(\n  std_diff_strat, \n  pvals_wide,\n  by = \"covariate\", \n  all = TRUE\n)\n\n# Mark significant values with asterisks directly in the data\nstrat_balance_table <- strat_balance_table %>%\n  mutate(\n    std_diff_mark = ifelse(abs(std_diff) > 0.25, \n                           paste0(format(round(std_diff, 3), nsmall=3), \"†\"), \n                           format(round(std_diff, 3), nsmall=3)),\n    `t-test_mark` = ifelse(`t-test` < 0.05, \n                          paste0(format(round(`t-test`, 3), nsmall=3), \"*\"), \n                          format(round(`t-test`, 3), nsmall=3)),\n    `OLS (no strata FE)_mark` = ifelse(`OLS (no strata FE)` < 0.05, \n                                      paste0(format(round(`OLS (no strata FE)`, 3), nsmall=3), \"*\"), \n                                      format(round(`OLS (no strata FE)`, 3), nsmall=3)),\n    `OLS (with strata FE)_mark` = ifelse(`OLS (with strata FE)` < 0.05, \n                                        paste0(format(round(`OLS (with strata FE)`, 3), nsmall=3), \"*\"), \n                                        format(round(`OLS (with strata FE)`, 3), nsmall=3))\n  )\n\n# Create gt table with the marked columns\nstrat_balance_table %>%\n  select(covariate, std_diff_mark, `t-test_mark`, `OLS (no strata FE)_mark`, `OLS (with strata FE)_mark`) %>%\n  gt() %>%\n  # Rename columns\n  cols_label(\n    covariate = \"Baseline Covariate\",\n    std_diff_mark = \"Standardized Difference\",\n    `t-test_mark` = \"t-test\",\n    `OLS (no strata FE)_mark` = \"OLS (standard)\",\n    `OLS (with strata FE)_mark` = \"OLS (with strata FE)\"\n  ) %>%\n  # Add column spanners for organization\n  tab_spanner(\n    label = \"Balance Measure\",\n    columns = \"std_diff_mark\"\n  ) %>%\n  tab_spanner(\n    label = \"P-values by Testing Approach\",\n    columns = c(\"t-test_mark\", \"OLS (no strata FE)_mark\", \"OLS (with strata FE)_mark\")\n  ) %>%\n  # Add title and footnotes\n  tab_header(\n    title = \"Table 1: Balance Assessment in Stratified Randomization\",\n    subtitle = \"Comparison of Different Testing Approaches\"\n  ) %>%\n  tab_footnote(\n    footnote = \"† Standardized differences >0.25, indicating potential imbalance.\",\n    locations = cells_column_labels(columns = \"std_diff_mark\")\n  ) %>%\n  tab_footnote(\n    footnote = \"* P-values <0.05, indicating statistically significant differences.\",\n    locations = cells_column_spanners(spanners = \"P-values by Testing Approach\")\n  ) %>%\n  tab_footnote(\n    footnote = \"OLS with strata fixed effects is the most appropriate approach given the stratified design.\",\n    locations = cells_column_labels(columns = \"OLS (with strata FE)_mark\")\n  ) %>%\n  # Nicer formatting\n  tab_options(\n    column_labels.font.weight = \"bold\",\n    column_labels.background.color = \"#EEEEEE\",\n    table.width = pct(100),\n    heading.background.color = \"#E6F0FF\",\n    heading.title.font.size = px(16),\n    heading.subtitle.font.size = px(14)\n  )\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"pmtmutpmmk\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#pmtmutpmmk table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#pmtmutpmmk thead, #pmtmutpmmk tbody, #pmtmutpmmk tfoot, #pmtmutpmmk tr, #pmtmutpmmk td, #pmtmutpmmk th {\n  border-style: none;\n}\n\n#pmtmutpmmk p {\n  margin: 0;\n  padding: 0;\n}\n\n#pmtmutpmmk .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: 100%;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#pmtmutpmmk .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#pmtmutpmmk .gt_title {\n  color: #333333;\n  font-size: 16px;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#pmtmutpmmk .gt_subtitle {\n  color: #333333;\n  font-size: 14px;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#pmtmutpmmk .gt_heading {\n  background-color: #E6F0FF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pmtmutpmmk .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pmtmutpmmk .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pmtmutpmmk .gt_col_heading {\n  color: #333333;\n  background-color: #EEEEEE;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#pmtmutpmmk .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #EEEEEE;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#pmtmutpmmk .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#pmtmutpmmk .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#pmtmutpmmk .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#pmtmutpmmk .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#pmtmutpmmk .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#pmtmutpmmk .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pmtmutpmmk .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#pmtmutpmmk .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#pmtmutpmmk .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#pmtmutpmmk .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pmtmutpmmk .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#pmtmutpmmk .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#pmtmutpmmk .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#pmtmutpmmk .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pmtmutpmmk .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#pmtmutpmmk .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#pmtmutpmmk .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pmtmutpmmk .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pmtmutpmmk .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#pmtmutpmmk .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pmtmutpmmk .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#pmtmutpmmk .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pmtmutpmmk .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pmtmutpmmk .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pmtmutpmmk .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pmtmutpmmk .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pmtmutpmmk .gt_left {\n  text-align: left;\n}\n\n#pmtmutpmmk .gt_center {\n  text-align: center;\n}\n\n#pmtmutpmmk .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#pmtmutpmmk .gt_font_normal {\n  font-weight: normal;\n}\n\n#pmtmutpmmk .gt_font_bold {\n  font-weight: bold;\n}\n\n#pmtmutpmmk .gt_font_italic {\n  font-style: italic;\n}\n\n#pmtmutpmmk .gt_super {\n  font-size: 65%;\n}\n\n#pmtmutpmmk .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#pmtmutpmmk .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#pmtmutpmmk .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#pmtmutpmmk .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#pmtmutpmmk .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#pmtmutpmmk .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#pmtmutpmmk .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#pmtmutpmmk .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#pmtmutpmmk div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_heading\">\n      <td colspan=\"5\" class=\"gt_heading gt_title gt_font_normal\" style>Table 1: Balance Assessment in Stratified Randomization</td>\n    </tr>\n    <tr class=\"gt_heading\">\n      <td colspan=\"5\" class=\"gt_heading gt_subtitle gt_font_normal gt_bottom_border\" style>Comparison of Different Testing Approaches</td>\n    </tr>\n    <tr class=\"gt_col_headings gt_spanner_row\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"2\" colspan=\"1\" scope=\"col\" id=\"covariate\">Baseline Covariate</th>\n      <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Balance Measure\">\n        <div class=\"gt_column_spanner\">Balance Measure</div>\n      </th>\n      <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"3\" scope=\"colgroup\" id=\"P-values by Testing Approach\">\n        <div class=\"gt_column_spanner\">P-values by Testing Approach<span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>1</sup></span></div>\n      </th>\n    </tr>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"std_diff_mark\">Standardized Difference<span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>2</sup></span></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"t-test_mark\">t-test</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"OLS-(no-strata-FE)_mark\">OLS (standard)</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"OLS-(with-strata-FE)_mark\">OLS (with strata FE)<span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>3</sup></span></th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"covariate\" class=\"gt_row gt_left\">age</td>\n<td headers=\"std_diff_mark\" class=\"gt_row gt_right\"> 0.012</td>\n<td headers=\"t-test_mark\" class=\"gt_row gt_right\">0.848</td>\n<td headers=\"OLS (no strata FE)_mark\" class=\"gt_row gt_right\">0.848</td>\n<td headers=\"OLS (with strata FE)_mark\" class=\"gt_row gt_right\">0.611</td></tr>\n    <tr><td headers=\"covariate\" class=\"gt_row gt_left\">chronic_disease</td>\n<td headers=\"std_diff_mark\" class=\"gt_row gt_right\">-0.087</td>\n<td headers=\"t-test_mark\" class=\"gt_row gt_right\">0.168</td>\n<td headers=\"OLS (no strata FE)_mark\" class=\"gt_row gt_right\">0.168</td>\n<td headers=\"OLS (with strata FE)_mark\" class=\"gt_row gt_right\">0.132</td></tr>\n    <tr><td headers=\"covariate\" class=\"gt_row gt_left\">education: Higher</td>\n<td headers=\"std_diff_mark\" class=\"gt_row gt_right\">-0.004</td>\n<td headers=\"t-test_mark\" class=\"gt_row gt_right\">0.952</td>\n<td headers=\"OLS (no strata FE)_mark\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"OLS (with strata FE)_mark\" class=\"gt_row gt_right\">NA</td></tr>\n    <tr><td headers=\"covariate\" class=\"gt_row gt_left\">education: Higher vs None</td>\n<td headers=\"std_diff_mark\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"t-test_mark\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"OLS (no strata FE)_mark\" class=\"gt_row gt_right\">0.952</td>\n<td headers=\"OLS (with strata FE)_mark\" class=\"gt_row gt_right\">NA</td></tr>\n    <tr><td headers=\"covariate\" class=\"gt_row gt_left\">education: None</td>\n<td headers=\"std_diff_mark\" class=\"gt_row gt_right\"> 0.004</td>\n<td headers=\"t-test_mark\" class=\"gt_row gt_right\">0.955</td>\n<td headers=\"OLS (no strata FE)_mark\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"OLS (with strata FE)_mark\" class=\"gt_row gt_right\">NA</td></tr>\n    <tr><td headers=\"covariate\" class=\"gt_row gt_left\">education: Primary</td>\n<td headers=\"std_diff_mark\" class=\"gt_row gt_right\">-0.005</td>\n<td headers=\"t-test_mark\" class=\"gt_row gt_right\">0.932</td>\n<td headers=\"OLS (no strata FE)_mark\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"OLS (with strata FE)_mark\" class=\"gt_row gt_right\">NA</td></tr>\n    <tr><td headers=\"covariate\" class=\"gt_row gt_left\">education: Primary vs None</td>\n<td headers=\"std_diff_mark\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"t-test_mark\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"OLS (no strata FE)_mark\" class=\"gt_row gt_right\">0.932</td>\n<td headers=\"OLS (with strata FE)_mark\" class=\"gt_row gt_right\">NA</td></tr>\n    <tr><td headers=\"covariate\" class=\"gt_row gt_left\">education: Secondary</td>\n<td headers=\"std_diff_mark\" class=\"gt_row gt_right\"> 0.006</td>\n<td headers=\"t-test_mark\" class=\"gt_row gt_right\">0.925</td>\n<td headers=\"OLS (no strata FE)_mark\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"OLS (with strata FE)_mark\" class=\"gt_row gt_right\">NA</td></tr>\n    <tr><td headers=\"covariate\" class=\"gt_row gt_left\">education: Secondary vs None</td>\n<td headers=\"std_diff_mark\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"t-test_mark\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"OLS (no strata FE)_mark\" class=\"gt_row gt_right\">0.925</td>\n<td headers=\"OLS (with strata FE)_mark\" class=\"gt_row gt_right\">NA</td></tr>\n    <tr><td headers=\"covariate\" class=\"gt_row gt_left\">female</td>\n<td headers=\"std_diff_mark\" class=\"gt_row gt_right\">-0.071</td>\n<td headers=\"t-test_mark\" class=\"gt_row gt_right\">0.265</td>\n<td headers=\"OLS (no strata FE)_mark\" class=\"gt_row gt_right\">0.265</td>\n<td headers=\"OLS (with strata FE)_mark\" class=\"gt_row gt_right\">0.262</td></tr>\n    <tr><td headers=\"covariate\" class=\"gt_row gt_left\">income</td>\n<td headers=\"std_diff_mark\" class=\"gt_row gt_right\"> 0.033</td>\n<td headers=\"t-test_mark\" class=\"gt_row gt_right\">0.606</td>\n<td headers=\"OLS (no strata FE)_mark\" class=\"gt_row gt_right\">0.606</td>\n<td headers=\"OLS (with strata FE)_mark\" class=\"gt_row gt_right\">0.589</td></tr>\n    <tr><td headers=\"covariate\" class=\"gt_row gt_left\">rural</td>\n<td headers=\"std_diff_mark\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"t-test_mark\" class=\"gt_row gt_right\">0.634</td>\n<td headers=\"OLS (no strata FE)_mark\" class=\"gt_row gt_right\">0.634</td>\n<td headers=\"OLS (with strata FE)_mark\" class=\"gt_row gt_right\">0.620</td></tr>\n    <tr><td headers=\"covariate\" class=\"gt_row gt_left\">satisfaction</td>\n<td headers=\"std_diff_mark\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"t-test_mark\" class=\"gt_row gt_right\">0.526</td>\n<td headers=\"OLS (no strata FE)_mark\" class=\"gt_row gt_right\">0.526</td>\n<td headers=\"OLS (with strata FE)_mark\" class=\"gt_row gt_right\">0.597</td></tr>\n  </tbody>\n  \n  <tfoot class=\"gt_footnotes\">\n    <tr>\n      <td class=\"gt_footnote\" colspan=\"5\"><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>1</sup></span> * P-values &lt;0.05, indicating statistically significant differences.</td>\n    </tr>\n    <tr>\n      <td class=\"gt_footnote\" colspan=\"5\"><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>2</sup></span> † Standardized differences &gt;0.25, indicating potential imbalance.</td>\n    </tr>\n    <tr>\n      <td class=\"gt_footnote\" colspan=\"5\"><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>3</sup></span> OLS with strata fixed effects is the most appropriate approach given the stratified design.</td>\n    </tr>\n  </tfoot>\n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n### Interpreting Balance Results\n\nWhen reviewing balance tables, it's important to consider:\n\n1.  **Statistical vs. Practical Significance**: With large samples, even tiny differences can be statistically significant. Focus on the magnitude of differences (SMD) rather than p-values.\n\n2.  **Multiple Testing**: With many covariates, expect some to show \"significant\" differences by chance. This is why joint tests and SMDs are often more informative.\n\n3.  **Key Predictors**: Pay special attention to covariates that strongly predict outcomes. Imbalance on these variables is more concerning.\n\n4.  **Visual Inspection**: Sometimes graphical displays of covariate distributions can complement statistical tests. Consider density plots or boxplots comparing treatment and control.\n\n5.  **Overall Assessment**: Look at the pattern of results rather than focusing on any single test. If multiple measures suggest imbalance on important predictors, consider covariate adjustment in analysis.\n\nLet's create visual assessments of balance as well:\n\n# Plot the proportion treated in each stratum\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# Summarize treatment assignment by strata\nstrata_summary <- dt_strat[, .(\n  count = .N,\n  n_treated = sum(treatment),\n  pct_treated = mean(treatment) * 100\n), by = strata]\n\n\np <- ggplot(strata_summary, aes(x = factor(strata), y = pct_treated)) +\n  geom_col(fill = \"steelblue\") +\n  geom_hline(yintercept = 50, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Treatment Assignment by Strata in Stratified Randomization\",\n    subtitle = \"Red line indicates 50% treatment assignment\",\n    x = \"Strata ID\",\n    y = \"Percent Treated (%)\"\n  ) +\n  theme_minimal()\n\nprint(p)\n```\n\n::: {.cell-output-display}\n![](lec-2-2_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n# Compare age distribution by treatment status for all randomization methods\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(dt_bern, aes(x = factor(treatment), y = age)) +\n  geom_boxplot(fill = \"lightblue\") +\n  labs(\n    title = \"Age Distribution by Treatment (Bernoulli Randomization)\",\n    x = \"Treatment Status\",\n    y = \"Age\"\n  ) +\n  theme_minimal()\n\np2 <- ggplot(dt_cr, aes(x = factor(treatment), y = age)) +\n  geom_boxplot(fill = \"blue\") +\n  labs(\n    title = \"Age Distribution by Treatment (Complete Randomization)\",\n    x = \"Treatment Status\",\n    y = \"Age\"\n  ) +\n  theme_minimal()\n\np3 <- ggplot(dt_rerand_threshold, aes(x = factor(treatment), y = age)) +\n  geom_boxplot(fill = \"lightpink\") +\n  labs(\n    title = \"Age Distribution by Treatment (Re-randomization - Threshold)\",\n    x = \"Treatment Status\",\n    y = \"Age\"\n  ) +\n  theme_minimal()\n\np4 <- ggplot(dt_rerand_optimal, aes(x = factor(treatment), y = age)) +\n  geom_boxplot(fill = \"lightyellow\") +\n  labs(\n    title = \"Age Distribution by Treatment (Re-randomization - Optimization)\",\n    x = \"Treatment Status\",\n    y = \"Age\"\n  ) +\n  theme_minimal()\n\np5 <- ggplot(dt_strat, aes(x = factor(treatment), y = age)) +\n  geom_boxplot(fill = \"lightgreen\") +\n  labs(\n    title = \"Age Distribution by Treatment (Stratified Randomization)\",\n    x = \"Treatment Status\",\n    y = \"Age\"\n  ) +\n  theme_minimal()\n\np6 <- ggplot(dt_matched, aes(x = factor(treatment), y = age)) +\n  geom_boxplot(fill = \"lightsalmon\") +\n  labs(\n    title = \"Age Distribution by Treatment (Matched Randomization)\",\n    x = \"Treatment Status\",\n    y = \"Age\"\n  ) +\n  theme_minimal()\n\n# Print the boxplots\nprint(p1)\n```\n\n::: {.cell-output-display}\n![](lec-2-2_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n\n```{.r .cell-code}\nprint(p2)\n```\n\n::: {.cell-output-display}\n![](lec-2-2_files/figure-html/unnamed-chunk-19-2.png){width=672}\n:::\n\n```{.r .cell-code}\nprint(p3)\n```\n\n::: {.cell-output-display}\n![](lec-2-2_files/figure-html/unnamed-chunk-19-3.png){width=672}\n:::\n\n```{.r .cell-code}\nprint(p4)\n```\n\n::: {.cell-output-display}\n![](lec-2-2_files/figure-html/unnamed-chunk-19-4.png){width=672}\n:::\n\n```{.r .cell-code}\nprint(p5)\n```\n\n::: {.cell-output-display}\n![](lec-2-2_files/figure-html/unnamed-chunk-19-5.png){width=672}\n:::\n\n```{.r .cell-code}\nprint(p6)\n```\n\n::: {.cell-output-display}\n![](lec-2-2_files/figure-html/unnamed-chunk-19-6.png){width=672}\n:::\n:::\n\n\n\n# Visualize matched pairs (first 20 pairs)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize matched pairs (first 20 pairs) with jittering\nsample_pairs <- dt_matched[pair_id <= 20]\np6 <- ggplot(sample_pairs, aes(x = factor(pair_id), y = age, color = factor(treatment))) +\n  # Add jitter to horizontal position, keep vertical position exact\n  geom_point(position = position_jitter(width = 0.3, height = 0), size = 3) +\n  labs(\n    title = \"Age within Matched Pairs (First 20 Pairs)\",\n    x = \"Pair ID\",\n    y = \"Age\",\n    color = \"Treatment\"\n  ) +\n  scale_color_manual(values = c(\"0\" = \"blue\", \"1\" = \"red\"), labels = c(\"Control\", \"Treatment\")) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\nprint(p6)\n```\n\n::: {.cell-output-display}\n![](lec-2-2_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\n# Compare balance across methods with a p-value visualization\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nttest_strat <- run_ttests(dt_strat, \"Stratified - t-test\")\nttest_rerand_threshold <- run_ttests(dt_rerand_threshold, \"ReRand Threshold - t-test\")\nttest_rerand_optimal <- run_ttests(dt_rerand_optimal, \"ReRand Optimal - t-test\")\nttest_matched <- run_ttests(dt_matched, \"Matched - t-test\")\n\n# Combine all results\nall_ttest_results <- rbind(ttest_bern, ttest_cr, ttest_rerand_threshold, ttest_rerand_optimal, ttest_strat, ttest_matched)\n                           \nmethod_order <- c(\"Bernoulli - t-test\", \n                  \"Complete - t-test\",\n                  \"ReRand Threshold - t-test\", \n                  \"ReRand Optimal - t-test\",\n                  \"Stratified - t-test\", \n                  \"Matched - t-test\")\n\nbalance_viz_data <- all_ttest_results[method %in% method_order, \n                                    .(variable, method, p_value)]\n\n# Reorder methods for better visualization\nbalance_viz_data[, method := factor(method, levels = method_order)]\n\np7 <- ggplot(balance_viz_data, aes(x = method, y = reorder(variable, -p_value), fill = p_value)) +\n  geom_tile() +\n  scale_fill_gradient2(low = \"red\", mid = \"yellow\", high = \"green\", \n                      midpoint = 0.5, limits = c(0, 1)) +\n  geom_text(aes(label = round(p_value, 2)), color = \"black\", size = 2.5) +\n  labs(\n    title = \"Balance Test P-values Across Randomization Methods\",\n    x = \"Randomization Method\",\n    y = \"Variable\",\n    fill = \"P-value\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nprint(p7)\n```\n\n::: {.cell-output-display}\n![](lec-2-2_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\nThis combination of numerical metrics and visual displays provides a comprehensive assessment of balance.\n\n## Complex Experimental Designs\n\nBeyond the basic approaches, several complex randomization designs address specific research challenges:\n\n### Units of Randomization & Spillovers\n\nA critical decision is choosing what entity (e.g. person or cluster) to randomize:\n\n**Key considerations:**\n\n-   Match observational unit when possible\n-   Align with treatment delivery\n-   Minimize spillovers\n-   Consider statistical power\n\n**Common units:**\n\n-   **Individual**: Patients, students\n-   **Cluster**: Villages, clinics, schools\n-   **Time periods**: Days, weeks, shifts\n-   **Networks**: Households, peer groups\n\nThe tradeoff is often between statistical power (favoring individual randomization) and internal validity (which may require cluster randomization to minimize spillovers).\n\n### The Spillover Problem\n\nSpillovers occur when treatment affects untreated units, through:\n\n-   Direct interaction between units\n-   General equilibrium effects\n-   Information diffusion\n-   Resource competition\n\nWhen spillovers are a concern, randomization at a higher level (clustering) can help minimize unwanted contamination. Alternatively, a two-stage randomization design can help measure spillover effects explicitly.\n\n### Two-Stage Randomization for Measuring Spillovers\n\nThis approach:\n\n1.  First randomizes clusters to high or low treatment intensity\n2.  Then randomizes individuals within clusters to treatment or control\n\nThis design allows measurement of:\n\n-   Direct treatment effects\n-   Within-cluster spillovers\n-   Between-cluster spillovers\n\n### Cluster Randomization\n\nCluster randomization assigns groups rather than individuals to treatment conditions: (we saw this last unit)\n\n**Examples of clusters:**\n\n-   Schools\n-   Clinics\n-   Villages\n-   Neighborhoods\n\nThe key parameter affecting statistical power is the intraclass correlation coefficient (ICC), which measures how correlated outcomes are within clusters. The design effect formula shows how clustering reduces effective sample size:\n\n$$DE = 1 + (m-1) \\times ICC$$\n\nwhere $m$ is the average cluster size. A larger design effect means a larger required sample size to achieve the same power.\n\nAnalysis needs to account for clustering through one of:\n\n-   Cluster-robust standard errors\n-   Mixed-effects models\n-   Generalized estimating equations (GEE)\n\n### Factorial Designs: Testing Multiple Treatments\n\nFactorial designs test multiple interventions simultaneously:\n\n| Intervention B | No Intervention A | Intervention A |\n|----------------|-------------------|----------------|\n| **No**         | Control           | A only         |\n| **Yes**        | B only            | A and B        |\n\nThis approach:\n\n-   Tests multiple treatments simultaneously\n-   Estimates main effects AND interactions\n-   Uses resources efficiently\n\nFor example, with two interventions (A and B), we have four groups:\n\n-   No intervention (control)\n-   Intervention A only\n-   Intervention B only\n-   Both A and B\n\nFactorial designs are particularly valuable when:\n\n1.  You want to test combinations of interventions\n2.  You suspect treatments might interact (enhance or interfere with each other)\n3.  You need to maximize efficiency with limited resources\n\nHere's how we might implement a 2×2 factorial design in R:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\nset.seed(072311)\nn <- 200  # Total sample size\n\n# Create data table\ndt <- data.table(id = 1:n)\n\n# First randomization for factor A\ndt[, A := c(rep(1, n/2), rep(0, n/2))[sample(1:n)]]\n\n# Second randomization for factor B\ndt[, B := c(rep(1, n/2), rep(0, n/2))[sample(1:n)]]\n\n# Create combined treatment variable\ndt[, treatment := paste0(\"A\", A, \"B\", B)]\n\n# Check allocation\ndt[, .N, by = treatment]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   treatment     N\n      <char> <int>\n1:      A1B1    49\n2:      A0B1    51\n3:      A1B0    51\n4:      A0B0    49\n```\n\n\n:::\n:::\n\n\n\n### Randomized Phase-in Designs\n\nIn randomized phase-in designs, all units eventually receive treatment, but the timing of treatment is randomized.\n\n**Advantages:**\n\n-   Improves compliance since everyone gets treatment eventually\n-   Works well with resource constraints\n-   Offers a politically appealing compromise\n\n**Limitations:**\n\n-   May create anticipation effects\n-   Limits long-term impact measurement\n-   Eventually loses the control group\n\n### Adaptive Randomization\n\nAdaptive designs update assignment probabilities based on accumulated data, balancing:\n\n-   **Exploration**: Learning which treatment works best\n-   **Exploitation**: Assigning more units to better treatments\n\nThe key \\*ethical\\*\\* advantage is that fewer participants receive inferior treatments as evidence accumulates. We'll cover adaptive designs in more detail in a future lecture.\n\nA simple example of response-adaptive randomization might look like this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simplified response-adaptive randomization simulation\nsimulate_adaptive_randomization <- function(n_total = 100, \n                                          true_success_A = 0.3, \n                                          true_success_B = 0.5) {\n  # Initialize data storage\n  results <- data.frame(\n    id = 1:n_total,\n    treatment = NA,\n    outcome = NA\n  )\n  \n  # Initial equal assignment probabilities\n  prob_A <- 0.5\n  \n  # Track successes and failures\n  success_A <- 0\n  total_A <- 0\n  success_B <- 0\n  total_B <- 0\n  \n  # Simulate sequential enrollment\n  for (i in 1:n_total) {\n    # Assign treatment based on current probability\n    treatment <- sample(c(\"A\", \"B\"), 1, prob = c(prob_A, 1-prob_A))\n    results$treatment[i] <- treatment\n    \n    # Generate outcome based on true success rates\n    if (treatment == \"A\") {\n      outcome <- rbinom(1, 1, true_success_A)\n      success_A <- success_A + outcome\n      total_A <- total_A + 1\n    } else {\n      outcome <- rbinom(1, 1, true_success_B)\n      success_B <- success_B + outcome\n      total_B <- total_B + 1\n    }\n    results$outcome[i] <- outcome\n    \n    # Update probability for next assignment using Beta prior\n    if (i < n_total) {  # No need to update after last patient\n      # Beta-Bernoulli update (adding 1 for prior)\n      prob_A <- rbeta(1, success_A + 1, total_A - success_A + 1) /\n               (rbeta(1, success_A + 1, total_A - success_A + 1) + \n                rbeta(1, success_B + 1, total_B - success_B + 1))\n    }\n  }\n  \n  return(results)\n}\n```\n:::\n\n\n\n## Practical Implementation Tips\n\nRegardless of which randomization approach you choose, follow these best practices:\n\n1.  Create a single entry per randomization unit\n2.  Sort the file in a reproducible way\n3.  Set and preserve a random seed\n4.  Assign treatments\n5.  Save assignments securely\n6.  Test balance extensively\n\nAlways document your randomization procedure thoroughly to enhance transparency and reproducibility.\n\nBelow is a template for implementing and documenting randomization:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Randomization implementation template\n\n# 1. Document parameters\nstudy_name <- \"My Clinical Trial\"\nrandomization_date <- \"2025-02-25\"\nrandomization_conducted_by <- \"J. Smith\"\nrandom_seed <- 072311  # Document why this seed was chosen\nallocation_ratio <- 0.5  # Equal allocation\nstratification_variables <- c(\"site\", \"gender\")\n\n# 2. Set up reproducible environment\nset.seed(random_seed)\nlibrary(tidyverse)\n\n# 3. Load and prepare data\ndata <- read.csv(\"participant_data.csv\")\n\n# 4. Implement randomization\n# Example: stratified randomization\n\n\n# 5. Check balance\n# Generate Balance Table\n\n# 6. Save results securely\n# a) Save randomization details\nrandomization_log <- data.frame(\n  study_name = study_name,\n  date = randomization_date,\n  conducted_by = randomization_conducted_by,\n  seed = random_seed,\n  method = \"stratified\",\n  stratification_variables = paste(stratification_variables, collapse = \", \")\n)\nwrite.csv(randomization_log, \"randomization_log.csv\", row.names = FALSE)\n\n# b) Save assignment data\nwrite.csv(\n  data %>% select(id, treatment, stratum_id), \n  \"treatment_assignments.csv\", \n  row.names = FALSE\n)\n\n# c) Save balance checks\nwrite.csv(balance_table, \"balance_checks.csv\", row.names = FALSE)\n```\n:::\n\n\n\n## Ethical Considerations in Randomization\n\nRandomization raises several ethical considerations:\n\n-   **Long-term benefits** vs. short-term resource distribution\n-   **Equity** in who receives potentially beneficial treatments\n-   **Transparency** with participants about randomization\n-   **Minimizing harm** from potentially ineffective interventions\n\nThese issues must be carefully considered and addressed in the design phase. Specific approaches that can address ethical concerns include:\n\n1.  **Randomized phase-in designs**: Ensures everyone eventually receives the intervention\n2.  **Adaptive randomization**: Skews allocation toward better-performing treatments over time\n3.  **Risk-based randomization**: Targets interventions toward those most likely to benefit (we'll cover in the future if time)\n4.  **Minimization of control group size**: Uses unequal allocation ratios to minimize the number of participants not receiving intervention (could add this consideration to optimal allocation)\n\n## Conclusion: Which Method When?\n\nThere is no one-size-fits-all approach. The best randomization strategy depends on:\n\n-   The research question\n-   Available baseline data\n-   Logistical constraints\n-   Expected heterogeneity in treatment effects\n\n| Approach         | When to Use              | Key Consideration          |\n|------------------|--------------------------|----------------------------|\n| Simple           | Large samples            | Simplicity                 |\n| Stratified       | Strong predictors known  | Number of strata           |\n| Matched-Pair     | Small samples            | Finding good matches       |\n| Re-randomization | Balance is critical      | Complexity of inference    |\n| Cluster          | Group-level intervention | ICC and number of clusters |\n\nThe choice of randomization method should be guided by:\n\n1.  The unit of randomization (individual vs. cluster)\n2.  The importance of balance on specific variables\n3.  Feasibility constraints\n4.  Analysis plans\n\nHappy randomizing!",
    "supporting": [
      "lec-2-2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}