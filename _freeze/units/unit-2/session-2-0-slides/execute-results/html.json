{
  "hash": "de23a42ef4d27587dcf604a03fd7b38e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Machine Learning Foundations for Causal Inference\"\nsubtitle: \"Session 2.0: Just-in-Time ML Refresher\"\nauthor: \"Sean Sylvia\"\ndate: \"2026-01-27\"\nformat:\n  revealjs:\n    theme: [default, ../../style/gillings.scss]\n    slide-number: true\n    chalkboard: true\n    transition: fade\n    progress: true\n    incremental: false\n    toc: false\n    scrollable: false\n    smaller: false\n    footer: \"HPM 883 | Session 2.0: ML Foundations\"\n    logo: ../../assets/gillings-logo.png\n    title-slide-attributes:\n      data-background-gradient: \"linear-gradient(135deg, #13294B 0%, #4B9CD3 100%)\"\n---\n\n# Learning Objectives\n\n## By the end of this session, you will...\n\n1. **Distinguish** prediction problems from estimation problems\n2. **Explain** the bias-variance tradeoff and cross-validation\n3. **Describe** regularization methods (Lasso, Ridge) and tree-based methods\n4. **Recognize** why ML is valuable for nuisance estimation in causal inference\n5. **Connect** ML tools to their roles in DML\n\n::: notes\nFrame this as a targeted refresher, not comprehensive ML course.\nKey question: \"Why do we need ML in causal inference?\"\n:::\n\n---\n\n# Part 1: Prediction vs. Estimation\n\n## The Two Tasks of Data Science\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n### Prediction (Y-hard)\n\n**Goal:** Best guess of Y for new X\n\n- Minimize out-of-sample error\n- Don't care about coefficients\n- Cross-validation for tuning\n\n**Examples:**\n- Hospital readmission risk\n- Credit default prediction\n- Image classification\n:::\n\n::: {.column width=\"50%\"}\n### Estimation (β-hard)\n\n**Goal:** Recover structural parameters\n\n- Identify causal effects\n- Coefficients are interpretable\n- Need identifying assumptions\n\n**Examples:**\n- Treatment effect of a drug\n- Price elasticity\n- Returns to education\n:::\n\n::::\n\n::: notes\nThis distinction is fundamental. ML excels at Y-hard; we need more for β-hard.\n:::\n\n---\n\n## Why Can't ML Solve Causal Questions?\n\n::: {.callout-warning}\n## The Fundamental Problem\nML learns correlations in data. Correlation ≠ Causation.\n:::\n\n::: fragment\n**Example:** A model predicting hospital costs might find:\n\n- Patients with higher costs have more medications\n- Prediction: \"More meds → higher costs\"\n\nBut causally, medications might *reduce* costs by preventing complications!\n:::\n\n::: fragment\n**ML sees:** $\\text{Corr}(Meds, Costs) > 0$\n\n**Reality:** $\\text{Causal Effect}(Meds \\to Costs) < 0$ (possibly)\n:::\n\n---\n\n## The Prediction-Causation Gap\n\n```{mermaid}\n%%| fig-width: 10\nflowchart LR\n    subgraph ML[\"ML Prediction\"]\n        X[Features X] --> M[ML Model] --> Y[\"Ŷ (prediction)\"]\n    end\n\n    subgraph CI[\"Causal Inference\"]\n        D[Treatment D] --> E[Causal Effect τ] --> O[Outcome Y]\n        C[Confounders X] --> D\n        C --> O\n    end\n\n    style ML fill:#e3f2fd,stroke:#1976d2\n    style CI fill:#fff3e0,stroke:#f57c00\n```\n\n::: fragment\n**Key insight:** ML can estimate the relationships in the causal graph, but can't identify the causal effect without additional structure.\n:::\n\n---\n\n## When ML Is Enough\n\nML *is* sufficient for pure prediction tasks:\n\n::: incremental\n- **Risk stratification:** Which patients are high-risk?\n- **Resource targeting:** Who should receive an intervention?\n- **Screening:** Which cases need human review?\n- **Forecasting:** What will demand be next month?\n:::\n\n::: fragment\n::: {.callout-tip}\n## The Question Test\nIf \"Why?\" doesn't matter, only \"What will happen?\", ML may be enough.\n:::\n:::\n\n---\n\n## When We Need Causal Methods\n\nWe need causal inference when:\n\n::: incremental\n- **Counterfactuals matter:** What *would* happen under intervention?\n- **Policy evaluation:** What's the effect of a policy change?\n- **Attribution:** Did the treatment cause the outcome?\n- **Mechanism design:** How to optimize intervention assignment?\n:::\n\n::: fragment\n**Good news:** ML can *help* with causal inference—as a tool for nuisance estimation.\n:::\n\n---\n\n# Part 2: ML Fundamentals\n\n## The Bias-Variance Tradeoff\n\n$$\\text{Expected MSE} = \\text{Bias}^2 + \\text{Variance} + \\text{Irreducible Error}$$\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n**Bias (Underfitting)**\n\n- Model too simple\n- Misses true structure\n- Systematic errors\n\n*Example:* Linear model for nonlinear data\n:::\n\n::: {.column width=\"50%\"}\n**Variance (Overfitting)**\n\n- Model too complex\n- Fits noise in training data\n- Unstable across samples\n\n*Example:* Deep tree memorizing data\n:::\n\n::::\n\n---\n\n## Visualizing the Tradeoff\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](session-2-0-slides_files/figure-revealjs/unnamed-chunk-2-1.png){fig-alt='Bias-variance tradeoff showing optimal model complexity. As complexity increases, bias decreases but variance increases. Total error is minimized at an intermediate complexity level.' width=960}\n:::\n:::\n\n\n---\n\n## Cross-Validation: Finding the Sweet Spot\n\n**K-fold cross-validation:**\n\n```{mermaid}\n%%| fig-width: 10\nflowchart LR\n    subgraph \"Fold 1\"\n        T1[Train: 2-5] --> V1[Valid: 1]\n    end\n    subgraph \"Fold 2\"\n        T2[Train: 1,3-5] --> V2[Valid: 2]\n    end\n    subgraph \"...\"\n        T3[...] --> V3[...]\n    end\n    subgraph \"Fold 5\"\n        T5[Train: 1-4] --> V5[Valid: 5]\n    end\n\n    V1 & V2 & V3 & V5 --> Avg[Average Error]\n```\n\n::: fragment\n**Purpose:** Estimate out-of-sample performance for:\n1. Model selection (which algorithm?)\n2. Hyperparameter tuning (which λ?)\n3. Performance estimation (how good is the model?)\n:::\n\n---\n\n## Why Cross-Validation Matters for DML\n\n::: {.callout-important}\n## Cross-Fitting in DML\nIn Double ML, we use **cross-fitting** (sample splitting) to prevent overfitting bias from contaminating causal estimates.\n:::\n\n::: fragment\nWithout cross-fitting:\n- ML models overfit to training data\n- This bias leaks into causal estimates\n- Standard errors are invalid\n\nWith cross-fitting:\n- Predictions made on held-out samples\n- No overfitting bias in causal estimates\n- Valid inference\n:::\n\n---\n\n## Regularization: Controlling Complexity\n\n**Problem:** With many predictors, OLS overfits (high variance).\n\n**Solution:** Add a penalty that shrinks coefficients.\n\n::: fragment\n**Lasso (L1 penalty):**\n$$\\min_\\beta \\sum_{i=1}^n (y_i - X_i\\beta)^2 + \\lambda \\sum_{j=1}^p |\\beta_j|$$\n\n- Shrinks some coefficients to exactly zero\n- Performs variable selection\n:::\n\n::: fragment\n**Ridge (L2 penalty):**\n$$\\min_\\beta \\sum_{i=1}^n (y_i - X_i\\beta)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2$$\n\n- Shrinks all coefficients (no exact zeros)\n- Good when all predictors contribute\n:::\n\n---\n\n## Lasso: Geometric Intuition\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\nThe diamond-shaped constraint region creates corners where some $\\beta_j = 0$.\n\n**Result:** Automatic variable selection\n\n**Choosing λ:** Cross-validation!\n\n- Small λ: Less shrinkage, more variance\n- Large λ: More shrinkage, more bias\n:::\n\n::: {.column width=\"55%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](session-2-0-slides_files/figure-revealjs/unnamed-chunk-4-1.png){fig-alt='Lasso constraint region (diamond) intersecting with RSS contours. The solution occurs at a corner where beta_1 = 0.' width=480}\n:::\n:::\n\n:::\n\n::::\n\n---\n\n# Part 3: Tree-Based Methods\n\n## Decision Trees: Intuition\n\nTrees recursively partition the predictor space:\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n```{mermaid}\nflowchart TD\n    A[Age > 60?] --> |Yes| B[High Risk]\n    A --> |No| C[Income > 50K?]\n    C --> |Yes| D[Low Risk]\n    C --> |No| E[Medium Risk]\n\n    classDef high fill:#f8cecc,stroke:#333\n    classDef low fill:#d5e8d4,stroke:#333\n    classDef med fill:#fff2cc,stroke:#333\n\n    class B high\n    class D low\n    class E med\n```\n:::\n\n::: {.column width=\"60%\"}\n**Advantages:**\n- No functional form assumptions\n- Automatic interactions\n- Highly interpretable\n\n**Disadvantages:**\n- High variance (unstable)\n- Overfit easily if unpruned\n- Limited accuracy alone\n:::\n\n::::\n\n---\n\n## Random Forests: Wisdom of Crowds\n\n**Problem:** Single trees have high variance.\n\n**Solution:** Average many trees!\n\n::: incremental\n1. **Bootstrap:** Draw B samples with replacement\n2. **Random subsets:** At each split, consider only m predictors\n3. **Aggregate:** Average predictions (regression) or vote (classification)\n:::\n\n::: fragment\n::: {.callout-tip}\n## Why It Works\nAveraging many uncorrelated high-variance estimators reduces variance without increasing bias.\n:::\n:::\n\n---\n\n## Gradient Boosting (XGBoost)\n\n**Different philosophy:** Build trees sequentially, each correcting previous errors.\n\n```{mermaid}\n%%| fig-width: 10\nflowchart LR\n    Y[Y] --> T1[Tree 1]\n    T1 --> R1[Residuals]\n    R1 --> T2[Tree 2]\n    T2 --> R2[Residuals]\n    R2 --> T3[Tree 3]\n    T3 --> dots[...]\n    dots --> Final[\"Final: Σ Trees\"]\n```\n\n::: fragment\n**Tuning parameters:**\n- **Number of trees** (B): More = better fit, but can overfit\n- **Learning rate** (λ): Smaller = more robust, needs more trees\n- **Tree depth**: Usually shallow (3-6)\n:::\n\n---\n\n## Random Forest vs. XGBoost\n\n| Aspect | Random Forest | XGBoost |\n|--------|---------------|---------|\n| Trees | Independent (parallel) | Sequential |\n| Strategy | Average out errors | Correct errors |\n| Overfitting | Less prone | More careful tuning needed |\n| Tuning | Easier | More hyperparameters |\n| Performance | Very good | Often best (if tuned well) |\n\n::: fragment\n**In practice:** Both are excellent for nuisance estimation in DML.\n:::\n\n---\n\n# Part 4: ML as a Tool for Causal Inference\n\n## The DML Insight\n\nIn causal inference, we want to estimate $\\tau$ (treatment effect).\n\nTraditional approach struggles when:\n- Many confounders (high-dimensional X)\n- Unknown functional forms\n- Regularization introduces bias in $\\hat{\\tau}$\n\n::: fragment\n::: {.callout-note}\n## The Double ML Solution\nUse ML to estimate **nuisance functions**, not the treatment effect directly.\nThen use orthogonal scores to recover $\\hat{\\tau}$ without regularization bias.\n:::\n:::\n\n---\n\n## Nuisance Functions in DML\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n### Propensity Score\n$$e(X) = P(D=1|X)$$\n\n- Probability of treatment given X\n- Estimated by ML (logistic, forest, etc.)\n- Used for weighting or adjustment\n:::\n\n::: {.column width=\"50%\"}\n### Outcome Regression\n$$\\mu(d, X) = E[Y|D=d, X]$$\n\n- Expected outcome given D and X\n- Estimated by ML (any method)\n- Used for imputation or adjustment\n:::\n\n::::\n\n::: fragment\n**Key:** We don't interpret these functions—we just need good predictions!\n:::\n\n---\n\n## Why ML Helps Causal Inference\n\n```{mermaid}\n%%| fig-width: 12\nflowchart LR\n    subgraph \"Traditional\"\n        D1[Data] --> R1[Parametric\\nRegression] --> B1[\"τ̂ (possibly biased)\"]\n    end\n\n    subgraph \"Double ML\"\n        D2[Data] --> ML[ML\\nNuisance Est.]\n        ML --> e[\"ê(X)\"]\n        ML --> mu[\"μ̂(X)\"]\n        e --> OS[Orthogonal\\nScore]\n        mu --> OS\n        OS --> B2[\"τ̂ (root-n consistent)\"]\n    end\n\n    style Traditional fill:#fff3e0\n    style B1 fill:#f8cecc\n    style B2 fill:#d5e8d4\n```\n\n---\n\n## The Magic: Cross-Fitting\n\n::: {.callout-important}\n## Why Cross-Fitting?\nML predictions overfit to training data. If we use these predictions to estimate $\\tau$, overfitting bias leaks through.\n:::\n\n::: fragment\n**Solution:** Cross-fitting\n\n1. Split data into K folds\n2. For each fold k: train ML on other folds, predict on fold k\n3. All predictions are out-of-sample → no overfitting bias\n:::\n\n::: fragment\nThis is the \"secret sauce\" that makes ML + causal inference work!\n:::\n\n---\n\n## R Packages You'll Use\n\n```r\n# ML for nuisance estimation\nlibrary(glmnet)     # Lasso, Ridge, Elastic Net\nlibrary(ranger)     # Random Forests (fast)\nlibrary(xgboost)    # Gradient Boosting\n\n# Causal ML\nlibrary(DoubleML)   # Double Machine Learning\nlibrary(grf)        # Causal Forests, Generalized RF\n\n# Workflow\nlibrary(tidymodels) # Unified ML interface\nlibrary(caret)      # Alternative workflow\n```\n\n---\n\n## Preview: DML in Action\n\n```r\n# Coming in Session 2.1!\nlibrary(DoubleML)\n\n# Specify ML learners for nuisance estimation\nml_g <- lrn(\"regr.ranger\")    # Outcome regression: random forest\nml_m <- lrn(\"classif.ranger\") # Propensity score: random forest\n\n# Create DML data object\ndml_data <- DoubleMLData$new(data, y_col = \"outcome\",\n                              d_col = \"treatment\", x_cols = covariates)\n\n# Estimate treatment effect\ndml_plr <- DoubleMLPLR$new(dml_data, ml_g, ml_m)\ndml_plr$fit()\ndml_plr$summary()\n```\n\n---\n\n# Key Takeaways\n\n## Summary\n\n1. **Prediction ≠ Causation.** ML predicts Y; causal inference requires more.\n\n2. **Bias-variance tradeoff.** Regularization and cross-validation find the sweet spot.\n\n3. **Lasso & Ridge.** Control complexity via coefficient shrinkage.\n\n4. **Ensembles reduce variance.** Random forests and boosting outperform single models.\n\n5. **In DML, ML serves causality.** Use ML's predictive power for nuisance estimation, then recover causal effects through orthogonal estimation.\n\n---\n\n## For Next Time\n\n### Session 2.1: Influence Functions & Orthogonal Scores\n\n**Preparation:**\n- Read: Chernozhukov Ch. 4 (Orthogonal Moments)\n- Read: Kennedy (2016) tutorial on influence functions\n\n**Key question:** How do we construct estimators that are robust to small errors in ML predictions?\n\n---\n\n## Questions? {.center}\n\n::: {.r-fit-text}\nOffice Hours: Wednesdays 2-4pm, McGavran-Greenberg 2101E\n\nEmail: ssylvia@unc.edu\n:::\n\n---\n\n# Appendix {visibility=\"uncounted\"}\n\n## Additional Resources\n\n**Remedial:**\n- StatQuest ML playlist\n- ISLR online course (free)\n\n**Advanced:**\n- Elements of Statistical Learning (ESL)\n- Athey & Imbens (2019) survey\n\n## References\n\n::: {#refs}\n:::\n",
    "supporting": [
      "session-2-0-slides_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}