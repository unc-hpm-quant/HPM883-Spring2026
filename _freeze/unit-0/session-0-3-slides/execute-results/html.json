{
  "hash": "334085d7d53b236cc7d863bd898eeb4f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Session 0.3: Potential Outcomes & Structural Causal Models\"\nsubtitle: \"Unit 0: Foundations\"\nauthor: \"Sean Sylvia\"\ndate: \"January 14, 2026\"\ndate-format: long\nformat:\n  revealjs:\n    theme: [default, ../style/gillings.scss]\n    slide-number: true\n    chalkboard: true\n    preview-links: auto\n    logo: ../images/logo.png\n    footer: \"HPM 883 | Session 0.3\"\n    transition: fade\n    incremental: false\n    smaller: true\n    scrollable: true\n    toc: true\n    toc-depth: 1\n    code-fold: false\n    highlight-style: github\nexecute:\n  echo: true\n  warning: false\n  message: false\n---\n\n## Today's Agenda {.center}\n\n1. Deep dive into potential outcomes\n2. Counterfactual reasoning\n3. Directed Acyclic Graphs (DAGs)\n4. d-Separation and identification\n5. Confounding vs. selection bias\n\n::: {.notes}\nThis is conceptual and mathematical. Heavy on notation but essential for everything that follows.\n:::\n\n---\n\n## The Fundamental Problem of Causal Inference\n\n### Patient i receives treatment\n\n| | Treated (Z=1) | Control (Z=0) |\n|---|:---:|:---:|\n| **Observed** | $Y_i(1)$ | ? |\n| **Counterfactual** | ? | $Y_i(0)$ |\n\n::: {.fragment}\n### The Problem\n\nWe can never observe both $Y_i(1)$ and $Y_i(0)$ for the same unit.\n\nIndividual treatment effect $\\tau_i = Y_i(1) - Y_i(0)$ is **unobservable**.\n:::\n\n---\n\n## Potential Outcomes Notation\n\n### Definition\n\nFor each unit $i$:\n\n- $Y_i(1)$ = outcome if treated (potential outcome under treatment)\n- $Y_i(0)$ = outcome if control (potential outcome under control)\n- $Z_i$ = treatment indicator (1 = treated, 0 = control)\n\n::: {.fragment}\n### Observed Outcome\n\n$$Y_i = Z_i \\cdot Y_i(1) + (1 - Z_i) \\cdot Y_i(0)$$\n\nWe only see *one* potential outcome for each unit.\n:::\n\n---\n\n## Treatment Effects\n\n### Individual Treatment Effect (ITE)\n\n$$\\tau_i = Y_i(1) - Y_i(0)$$\n\n**Unobservable** — would need to see same unit in both states\n\n::: {.fragment}\n### Average Treatment Effect (ATE)\n\n$$\\tau_{ATE} = E[Y_i(1) - Y_i(0)] = E[Y_i(1)] - E[Y_i(0)]$$\n\n**Observable** — with the right design\n:::\n\n::: {.fragment}\n### Other Estimands\n\n- **ATT**: $E[Y(1) - Y(0) | Z = 1]$\n- **ATU**: $E[Y(1) - Y(0) | Z = 0]$\n- **CATE**: $E[Y(1) - Y(0) | X = x]$\n:::\n\n---\n\n## The Selection Problem\n\n### Naive Comparison\n\n$$\\hat{\\tau}_{naive} = E[Y | Z=1] - E[Y | Z=0]$$\n\n::: {.fragment}\n### Decomposition\n\n$$\n\\begin{aligned}\nE[Y | Z=1] - E[Y | Z=0] &= \\underbrace{E[Y(1) | Z=1] - E[Y(0) | Z=1]}_{\\text{ATT}} \\\\\n&+ \\underbrace{E[Y(0) | Z=1] - E[Y(0) | Z=0]}_{\\text{Selection Bias}}\n\\end{aligned}\n$$\n:::\n\n::: {.callout-warning}\n## Key Insight\nNaive comparison = Treatment effect + Selection bias\n\nWithout randomization, we can't separate them.\n:::\n\n---\n\n## Randomization Solves Selection\n\n### Under Randomization\n\n$$Z \\perp\\!\\!\\!\\perp \\{Y(0), Y(1)\\}$$\n\nTreatment is **independent** of potential outcomes.\n\n::: {.fragment}\n### Consequence\n\n$$\n\\begin{aligned}\nE[Y(0) | Z=1] &= E[Y(0) | Z=0] = E[Y(0)] \\\\\nE[Y(1) | Z=1] &= E[Y(1) | Z=0] = E[Y(1)]\n\\end{aligned}\n$$\n\nSelection bias = 0!\n:::\n\n---\n\n## The Identification Assumption\n\n### Unconfoundedness (Ignorability)\n\n$$\\{Y(0), Y(1)\\} \\perp\\!\\!\\!\\perp Z | X$$\n\nGiven covariates $X$, treatment is as-if random.\n\n::: {.fragment}\n### What This Means\n\n- All confounders are measured\n- No unmeasured common causes\n- Allows causal interpretation in observational data\n- **Strong and untestable assumption**\n:::\n\n---\n\n## Stability Assumption (SUTVA)\n\n### Stable Unit Treatment Value Assumption\n\nTwo components:\n\n1. **No interference**: $Y_i$ depends only on $Z_i$, not $Z_j$ for $j \\neq i$\n\n2. **No hidden versions**: Treatment is well-defined\n\n::: {.fragment}\n### When SUTVA Fails\n\n- **Interference**: Vaccines (herd immunity)\n- **Hidden versions**: \"Job training\" means many things\n- **Spillovers**: Treated patients share rooms with controls\n:::\n\n---\n\n## Directed Acyclic Graphs (DAGs)\n\n### A Visual Language for Causal Assumptions\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](session-0-3-slides_files/figure-revealjs/unnamed-chunk-1-1.png){fig-align='center' width=384}\n:::\n:::\n\n\n**Notation:**\n- Nodes = Variables\n- Arrows = Direct causal effects\n- Missing arrows = No direct effect\n\n---\n\n## DAG Elements\n\n### Confounding\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](session-0-3-slides_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=384}\n:::\n:::\n\n\n$X$ creates **spurious association** between $Z$ and $Y$\n\n::: {.fragment}\n### Solution\n\nAdjust for $X$ (conditioning, regression, matching, weighting)\n:::\n\n---\n\n## Mediator\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](session-0-3-slides_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=384}\n:::\n:::\n\n\n$M$ is on the causal pathway from $Z$ to $Y$\n\n::: {.callout-warning}\n## Do NOT Adjust for Mediators\nAdjusting for $M$ blocks the causal effect you're trying to estimate!\n:::\n\n---\n\n## Collider\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](session-0-3-slides_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=384}\n:::\n:::\n\n\n$C$ is caused by both $Z$ and $Y$\n\n::: {.callout-danger}\n## Collider Bias\nAdjusting for $C$ **creates** spurious association between $Z$ and $Y$!\n\nClassic mistake in observational studies.\n:::\n\n---\n\n## d-Separation\n\n### Rules for Reading DAGs\n\nA path is **blocked** if it contains:\n\n1. A chain $A \\rightarrow B \\rightarrow C$ and we condition on $B$\n2. A fork $A \\leftarrow B \\rightarrow C$ and we condition on $B$\n3. A collider $A \\rightarrow B \\leftarrow C$ and we **don't** condition on $B$\n\n::: {.fragment}\n### Two Variables are d-Separated\n\nIf **all paths** between them are blocked.\n\nd-Separated variables are **conditionally independent**.\n:::\n\n---\n\n## Example: Complex DAG\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](session-0-3-slides_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n::: {.fragment}\n### Analysis\n\n- **Confounding path**: $Z \\leftarrow U \\rightarrow Y$ (blocked by conditioning on $U$, but $U$ unobserved!)\n- **Adjustment set**: Must include $X$; cannot adjust for unobserved $U$\n- **Problem**: Causal effect not identified without more assumptions\n:::\n\n---\n\n## Confounding vs. Selection Bias\n\n::: {.columns}\n::: {.column width=\"50%\"}\n### Confounding\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](session-0-3-slides_files/figure-revealjs/unnamed-chunk-6-1.png){width=288}\n:::\n:::\n\n\nA common **cause** creates spurious association\n:::\n\n::: {.column width=\"50%\"}\n### Selection Bias (Collider)\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](session-0-3-slides_files/figure-revealjs/unnamed-chunk-7-1.png){width=288}\n:::\n:::\n\n\nConditioning on a common **effect** creates spurious association\n:::\n:::\n\n---\n\n## Example: Selection Bias\n\n### \"Hospital patients who receive treatment X have worse outcomes\"\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](session-0-3-slides_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n::: {.fragment}\n### The Problem\n\nBy studying only hospital patients, we **condition on admission** (a collider).\n\nThis creates spurious negative association between treatment and outcomes.\n:::\n\n---\n\n## Structural Causal Models (SCMs)\n\n### Beyond DAGs: The Math\n\nAn SCM specifies:\n\n1. **Endogenous variables**: $V = \\{Y, Z, X, ...\\}$\n2. **Exogenous variables**: $U = \\{U_Y, U_Z, ...\\}$\n3. **Structural equations**: $Y = f_Y(pa(Y), U_Y)$\n\n::: {.callout-note}\n## Foundation\nSCMs and the do() operator were developed by [Pearl (2009)](https://doi.org/10.1017/CBO9780511803161), building on his earlier work on Bayesian networks and causal reasoning.\n:::\n\n::: {.fragment}\n### Example\n\n$$\n\\begin{aligned}\nX &= U_X \\\\\nZ &= g(X) + U_Z \\\\\nY &= \\beta Z + \\gamma X + U_Y\n\\end{aligned}\n$$\n:::\n\n---\n\n## Interventions in SCMs\n\n### The do() Operator\n\n$P(Y | do(Z=1))$ ≠ $P(Y | Z=1)$\n\n**do(Z=1)**: Set $Z=1$ by intervention, breaking all arrows into $Z$\n\n**Z=1**: Observe that $Z=1$, preserving all relationships\n\n::: {.fragment}\n### Graphically\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](session-0-3-slides_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=384}\n:::\n:::\n\n\n$do(Z=1)$ removes all arrows into $Z$\n:::\n\n---\n\n## The Adjustment Formula\n\n### Backdoor Criterion\n\nIf $X$ blocks all backdoor paths from $Z$ to $Y$:\n\n$$P(Y | do(Z)) = \\sum_x P(Y | Z, X=x) P(X=x)$$\n\n::: {.fragment}\n### In Practice\n\n1. Draw DAG\n2. Find adjustment set (backdoor criterion)\n3. Condition on adjustment set\n4. Estimate effect (regression, matching, weighting)\n:::\n\n---\n\n## Code Example: Simulating Confounding\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(tidyverse)\nset.seed(883)\n\nn <- 1000\n\n# Generate data with confounding\ndf <- tibble(\n  X = rnorm(n),                    # Confounder\n  Z = rbinom(n, 1, plogis(0.5*X)), # Treatment depends on X\n  Y0 = 2 + 1*X + rnorm(n),         # Potential outcome under control\n  Y1 = Y0 + 0.5,                   # True effect = 0.5\n  Y = ifelse(Z == 1, Y1, Y0)       # Observed outcome\n)\n```\n:::\n\n\n---\n\n## Naive vs. Adjusted Estimate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(estimatr)\n\n# Naive estimate (biased)\nnaive <- lm_robust(Y ~ Z, data = df)\n\n# Adjusted estimate (unbiased)\nadjusted <- lm_robust(Y ~ Z + X, data = df)\n\ntribble(\n  ~Estimator, ~Estimate, ~SE, ~True,\n  \"Naive\", coef(naive)[\"Z\"], naive$std.error[\"Z\"], 0.5,\n  \"Adjusted\", coef(adjusted)[\"Z\"], adjusted$std.error[\"Z\"], 0.5\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  Estimator Estimate     SE  True\n  <chr>        <dbl>  <dbl> <dbl>\n1 Naive        1.06  0.0879   0.5\n2 Adjusted     0.585 0.0648   0.5\n```\n\n\n:::\n:::\n\n\n::: {.fragment}\n**Lesson**: Adjusting for confounders removes bias!\n:::\n\n---\n\n## Visualizing Confounding\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(df, aes(x = X, y = Y, color = factor(Z))) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Confounding: Treated units have higher X\",\n       color = \"Treatment\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](session-0-3-slides_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n---\n\n## DAG Tools in R\n\n### Using ggdag\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggdag)\n\ndag <- dagify(\n  Y ~ Z + X,\n  Z ~ X,\n  exposure = \"Z\",\n  outcome = \"Y\"\n)\n\nggdag_adjustment_set(dag, node_size = 16) +\n  geom_dag_point(aes(color = adjusted), size = 16) +\n  scale_color_manual(values = c(\"unadjusted\" = gillings_navy, \"adjusted\" = gillings_carolina)) +\n  theme_dag() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](session-0-3-slides_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n---\n\n## Key Assumptions Summary\n\n| Assumption | Meaning | Testable? |\n|------------|---------|-----------|\n| SUTVA | No interference, well-defined treatment | Partially |\n| Unconfoundedness | No unmeasured confounders | No |\n| Positivity | All units have chance of treatment | Yes |\n| Consistency | Potential outcome = observed if treated | No |\n\n::: {.callout-important}\n## Critical Insight\nCausal inference requires **assumptions**. These assumptions are often untestable. Be explicit about what you're assuming.\n:::\n\n---\n\n## Practical Guidelines\n\n### When Drawing DAGs\n\n1. Include all common causes you can think of\n2. Ask domain experts\n3. Be explicit about what's unobserved\n4. Don't include mediators unless studying mechanisms\n5. Check for colliders before conditioning\n\n### When Making Assumptions\n\n1. State them clearly\n2. Justify them substantively\n3. Test robustness to violations\n4. Be honest about limitations\n\n---\n\n## Connection to Course\n\n### This Foundation Enables:\n\n| Unit | Method | Key Assumption |\n|------|--------|----------------|\n| 1 | RCTs | Randomization |\n| 2 | DML | Unconfoundedness + correct functional form |\n| 3 | Causal Forests | Unconfoundedness |\n| 5 | Observational ML | Strong ignorability |\n| 6 | DiD | Parallel trends |\n\n**Everything builds on potential outcomes and DAGs!**\n\n---\n\n## Key Takeaways\n\n1. **Potential outcomes** define causal effects as contrasts between possible worlds\n\n2. **Selection bias** arises when treatment is related to outcomes\n\n3. **DAGs** visualize causal assumptions and guide identification\n\n4. **d-Separation** tells us what we must adjust for (and what we must not!)\n\n5. **SCMs** formalize interventions with the do() operator\n\n---\n\n## For Next Time\n\n### Session 1.1: Statistical Conclusion Validity & Power (Wed Jan 21)\n\n**Readings:**\n\n- [Chernozhukov Ch. 3 (RCTs)](http://chapters.causalml-book.org/CausalML_chap_3.pdf)\n- [Gelman & Carlin (2014)](https://doi.org/10.1177/1745691614551642) on power analysis\n\n**Note:** No class Monday (MLK Day). Lab 0 due Sunday, January 19.\n\n---\n\n## Questions? {.center}\n\nOffice Hours: Wednesday 2-4pm\n\nSlack: #hpm883-help\n\n::: {.notes}\nThis is dense material. Expect questions. Encourage students to come to office hours if confused about DAGs.\n:::\n",
    "supporting": [
      "session-0-3-slides_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}