{
  "hash": "36a6256dda11a5a416bd67d2971cff3c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Session 0.1: Course Overview & Causal Inference Foundations\"\nsubtitle: \"HPM 883: Advanced Quantitative Methods\"\nauthor: \"Sean Sylvia\"\ndate: \"January 7, 2026\"\ndate-format: long\nformat:\n  revealjs:\n    theme: [default, ../style/gillings.scss]\n    slide-number: true\n    transition: fade\n    progress: true\n    chalkboard: true\n    smaller: true\n    scrollable: true\n    logo: ../images/logo.png\n    footer: \"HPM 883 | Session 0.1\"\n    toc: true\n    toc-depth: 1\n    preview-links: auto\n    incremental: false\nexecute:\n  echo: false\n  warning: false\n  message: false\n---\n\n## Welcome to HPM 883 {.center}\n\n**Advanced Quantitative Methods for Health Policy and Management**\n\nSpring 2026\n\n::: {.notes}\nWelcome students. This is the third course in the quantitative methods sequence. We're going to explore cutting-edge methods at the intersection of causal inference and machine learning.\n:::\n\n---\n\n## Today's Journey\n\n![Session 0.1 Roadmap](media/session-0-1-roadmap.png){fig-alt=\"Session roadmap showing today's flow: Course Overview, Assessment & Grading, Causal Inference Foundations, Course Framework, Next Steps\" width=\"100%\"}\n\n::: {.notes}\nLet me walk you through what we'll cover today. We'll start with course logistics and assessment, then dive into the core of what this course is about ‚Äî causal inference foundations. We'll close with the three-layer framework that structures the entire course.\n:::\n\n# Course Overview {.center}\n\n## Course Philosophy\n\n::: {.columns}\n::: {.column width=\"50%\"}\n### What This Course Is\n\n- **Applied focus**: Real health policy problems\n- **Modern methods**: Causal ML, not just regression\n- **Reproducible research**: Code that others can run\n- **AI-assisted analysis**: Learning to work *with* AI tools\n:::\n\n::: {.column width=\"50%\"}\n### What This Course Is Not\n\n- A statistics refresher (prerequisite: HPM 881-882)\n- Pure machine learning for prediction\n- Theory without application\n- AI doing your thinking for you\n:::\n:::\n\n::: {.notes}\nSet expectations early. This is an advanced course that builds on prior quantitative training. We'll use modern methods but always with a focus on causal questions that matter for health policy.\n:::\n\n---\n\n## Course Structure\n\n### Hybrid Format\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**In-Person Sessions (M/W)**\n\n- Lectures and theory\n- Discussion and Q&A\n- Location: Rosenau 228\n:::\n\n::: {.column width=\"50%\"}\n**Remote Sessions (Select Days)**\n\n- Hands-on coding labs\n- Implementation practice\n- Via Zoom\n:::\n:::\n\n::: fragment\n::: {.callout-note}\n## Format Varies by Session\nCheck the schedule ‚Äî some weeks are all in-person, some mix formats.\n:::\n:::\n\n---\n\n## Unit Structure (8 Units, 14 Weeks)\n\n| Unit | Topic | Weeks |\n|------|-------|-------|\n| 0 | Foundations | 1 |\n| 1 | Experimental Design | 2-3 |\n| 2 | DR & DML | 4-6 |\n| 3 | HTE & Causal Forests | 7-8 |\n| 4 | Policy Learning | 9 |\n| 5 | Observational ML | 10 |\n| 6 | DiD & Synthetic Controls | 11 |\n| 7 | Advanced Topics | 12 |\n| 8 | Capstone | 13-14 |\n\n---\n\n## Work Expectations\n\n### Credit Hour Requirements\n\n::: {.callout-note}\n## U.S. Department of Education Definition\nOne credit hour = 1 hour of direct instruction + **2 hours of out-of-class work** per week.\n:::\n\n::: fragment\n**For HPM 883 (3 credits):**\n\n| Activity | Hours/Week |\n|----------|-----------|\n| Class time | 2.5 hrs |\n| Reading | 1-1.5 hrs |\n| Problem sets / Labs | 3-4 hrs |\n| Capstone project | 1-2 hrs |\n| **Total** | **~8-10 hrs** |\n:::\n\n---\n\n## Communication Channels\n\n::: {.columns}\n::: {.column width=\"33%\"}\n### Slack\n**Primary channel**\n\n- Quick questions\n- Peer discussion\n- Code help\n- Announcements\n\n*Response: < 24 hrs*\n:::\n\n::: {.column width=\"33%\"}\n### Canvas\n**Official platform**\n\n- Submissions\n- Grades\n- Course materials\n- Gradescope\n\n*Check daily*\n:::\n\n::: {.column width=\"33%\"}\n### Email\n**When needed**\n\n- Scheduling\n- Personal matters\n- Administrative\n\n*Response: 48 hrs*\n:::\n:::\n\n---\n\n## Office Hours & Support\n\n| Resource | When | Where |\n|----------|------|-------|\n| **Office Hours** | Wed 2:00-4:00pm | McGavran-Greenberg 1101-D or Zoom |\n| **Coding Support** | Fri 10:00-11:00am | Zoom |\n| **TA** | By appointment | Email Bryan Nice |\n\n::: fragment\n::: {.callout-tip}\n## Best Practices\n- Come with specific questions or code snippets\n- Check Slack first ‚Äî someone may have answered already\n- Don't wait until the deadline to ask for help\n:::\n:::\n\n# Assessment & Grading {.center}\n\n## Assessment Structure\n\n| Component | Weight | Description |\n|-----------|--------|-------------|\n| Problem Sets | 30% | ~7 assignments, **best 4 count** |\n| Design Memos | 20% | 2 memos (10% each) |\n| Capstone Project | 40% | PAP, replication, or comparison |\n| Peer Review | 10% | Review one peer's project |\n\n::: {.callout-note}\n## Problem Set Policy\nYou submit ~7 problem sets; lowest 3 are dropped. This allows flexibility for illness, travel, or competing deadlines.\n:::\n\n---\n\n## Grading Scale\n\n::: {.columns}\n::: {.column width=\"50%\"}\n### Graduate School Scale\n\n| Grade | Range | Meaning |\n|-------|-------|---------|\n| **H** | 93-100 | High Pass |\n| **P** | 80-92 | Pass |\n| **L** | 70-79 | Low Pass |\n| **F** | 0-69 | Fail |\n:::\n\n::: {.column width=\"50%\"}\n### My Philosophy\n\n- **H** = Exceptional work, ready for publication\n- **P** = Strong graduate work (most students)\n- **L** = Below expectations; needs improvement\n- **F** = Did not meet requirements\n:::\n:::\n\n---\n\n## Capstone Project\n\n### Three Options\n\n::: {.columns}\n::: {.column width=\"33%\"}\n**Pre-Analysis Plan**\n\nWrite a complete PAP for a planned or hypothetical study\n\n- Full identification strategy\n- Power analysis\n- Estimation approach\n- HTE analysis\n:::\n\n::: {.column width=\"33%\"}\n**Replication + Extension**\n\nReplicate a published study and extend with causal ML\n\n- Reproduce main results\n- Apply DML/forests\n- Compare approaches\n:::\n\n::: {.column width=\"33%\"}\n**Methods Comparison**\n\nCompare methods on simulated or real data\n\n- Define DGP\n- Apply multiple methods\n- Benchmark performance\n:::\n:::\n\n::: fragment\n**Deliverables:** Paper (15-20 pages) + Code repository + 15-min presentation\n:::\n\n# The Central Question {.center}\n\n## Why Are We Here?\n\n> When does a health intervention **cause** an outcome to change?\n\n::: fragment\nThis is fundamentally different from:\n\n- \"Are intervention and outcome **associated**?\"\n- \"Can we **predict** outcomes from interventions?\"\n\n::: {.callout-important}\n## Key Insight\nPrediction ‚â† Causation. A model that predicts well may tell us nothing about what happens when we intervene.\n:::\n:::\n\n---\n\n## Prediction vs. Causal Estimation\n\n::: {.columns}\n::: {.column width=\"50%\"}\n### Prediction (≈∂)\n\n**Goal:** Forecast outcomes\n\n- Minimize prediction error\n- Any features allowed\n- Black box OK\n- \"What will happen?\"\n\n**Example:** Predict which patients will be readmitted\n:::\n\n::: {.column width=\"50%\"}\n### Causal Estimation (Œ≤ÃÇ)\n\n**Goal:** Estimate treatment effects\n\n- Unbiased estimation\n- Confounding matters\n- Interpretability needed\n- \"What if we intervene?\"\n\n**Example:** Does discharge planning *reduce* readmissions?\n:::\n:::\n\n::: fragment\n::: {.callout-warning}\n## Common Mistake\nUsing predictive models to make causal claims. Correlation in $\\hat{Y}$ ‚â† Causation in $\\hat{\\beta}$.\n:::\n:::\n\n# The Three-Layer Causal Inference Stack {.center}\n\n## Course Framework\n\n::: {.callout-note}\n## Organizing Principle\nThis three-layer stack is our pedagogical framework for the course ‚Äî a tool for understanding how methods relate.\n:::\n\n![Three-Layer Causal Inference Stack](images/three-layer-stack.png){fig-alt=\"Three-layer stack: Identification at bottom, Estimation in middle, Decision at top\" width=\"80%\"}\n\n---\n\n## Layer 1: Identification\n\n**The Question**: Under what assumptions can we interpret an estimate as causal?\n\n::: {.columns}\n::: {.column width=\"50%\"}\n### Tools\n- Potential outcomes framework\n- Directed Acyclic Graphs (DAGs)\n- Identification strategies\n:::\n\n::: {.column width=\"50%\"}\n### Course Coverage\n- Unit 0: Foundations\n- Unit 1: Experimental design\n- Unit 5-6: Observational strategies\n:::\n:::\n\n::: {.callout-note}\n## Identification First\nNo amount of sophisticated estimation can rescue a study with flawed identification.\n:::\n\n---\n\n## Layer 2: Estimation\n\n**The Question**: Given valid identification, how do we estimate effects efficiently?\n\n::: {.columns}\n::: {.column width=\"50%\"}\n### Tools\n- Double/Debiased ML\n- Doubly-robust estimation\n- Causal forests\n- Influence functions\n:::\n\n::: {.column width=\"50%\"}\n### Course Coverage\n- Unit 2: DR & DML\n- Unit 3: Heterogeneous effects\n- Units 5-6: Advanced methods\n:::\n:::\n\n::: {.callout-tip}\n## Modern Estimation\nML methods excel at high-dimensional nuisance estimation while preserving valid inference on causal parameters.\n:::\n\n---\n\n## Layer 3: Decision\n\n**The Question**: Given estimated effects, what action should we take?\n\n::: {.columns}\n::: {.column width=\"50%\"}\n### Tools\n- Policy learning\n- Treatment rules\n- Off-policy evaluation\n:::\n\n::: {.column width=\"50%\"}\n### Course Coverage\n- Unit 4: Policy learning\n- Unit 8: Capstone projects\n:::\n:::\n\n::: {.callout-warning}\n## Decision Under Uncertainty\nOptimal decisions depend not just on average effects, but on heterogeneity and constraints.\n:::\n\n# How ML Helps with Causal Inference {.center}\n\n## The Potential Outcomes Framework\n\n### The Fundamental Setup\n\nFor each unit $i$:\n\n- $Y_i(1)$: Outcome if unit receives treatment\n- $Y_i(0)$: Outcome if unit receives control\n- $D_i$: Treatment indicator (1 = treated, 0 = control)\n\n::: fragment\n### The Individual Treatment Effect\n\n$$\\tau_i = Y_i(1) - Y_i(0)$$\n\nThe causal effect for unit $i$ is the difference between what would happen under treatment versus control.\n\n::: {.notes}\nThis notation will be used throughout the course. Y(1) is the potential outcome under treatment, Y(0) under control. These are counterfactual outcomes‚Äîwe can only ever observe one for each unit.\n:::\n:::\n\n---\n\n## The Fundamental Problem of Causal Inference\n\n::: {.callout-warning}\n## The Problem\nWe can never observe both $Y_i(1)$ and $Y_i(0)$ for the same unit.\n:::\n\n| Unit | $Y_i(1)$ | $Y_i(0)$ | $\\tau_i$ |\n|------|----------|----------|----------|\n| 1    | 8        | ?        | ?        |\n| 2    | ?        | 5        | ?        |\n| 3    | 7        | ?        | ?        |\n| 4    | ?        | 6        | ?        |\n\n::: fragment\n**The missing data problem**: Every causal inference method is fundamentally about dealing with missing counterfactual outcomes.\n:::\n\n---\n\n## Solution 1: Randomization\n\n### Under Random Assignment\n\n$$\\text{ATE} = E[Y | D=1] - E[Y | D=0]$$\n\n**Why does this work?**\n\n::: fragment\nRandomization ensures treatment and control groups are *exchangeable*:\n\n$$E[Y(1) | D=1] = E[Y(1) | D=0] = E[Y(1)]$$\n\n$$E[Y(0) | D=1] = E[Y(0) | D=0] = E[Y(0)]$$\n\n::: {.callout-tip}\n## This is Unit 1\nExperimental design: power, randomization inference, blocking, variance reduction.\n:::\n:::\n\n---\n\n## Solution 2: Conditional Independence\n\n### When Randomization Isn't Possible\n\nWithout experiments, we need **conditional ignorability**:\n\n$$Y(1), Y(0) \\perp\\!\\!\\!\\perp D \\mid X$$\n\n\"After controlling for $X$, treatment is as good as random.\"\n\n::: fragment\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](session-0-1-slides_files/figure-revealjs/unnamed-chunk-1-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n**Control for X** ‚Üí Block the backdoor path ‚Üí Identify causal effect\n:::\n\n---\n\n## How ML Helps: Nuisance Estimation\n\n### The Problem with High-Dimensional X\n\nTraditional approach: Model $E[Y|D,X]$ parametrically\n\n::: fragment\n**But what if X is complex?**\n\n- Many covariates\n- Nonlinear relationships\n- Interactions\n:::\n\n::: fragment\n### The ML Solution: Double/Debiased ML\n\nUse ML to estimate **nuisance functions** (propensity score, outcome model) while preserving valid inference on $\\hat{\\tau}$.\n\n::: {.callout-tip}\n## This is Unit 2\nInfluence functions, orthogonal scores, cross-fitting.\n:::\n:::\n\n---\n\n## Beyond Averages: Treatment Effect Heterogeneity\n\n### Conditional Average Treatment Effect\n\n$$\\text{CATE}(x) = E[Y(1) - Y(0) | X = x]$$\n\nThe average effect for units with characteristics $X = x$.\n\n::: fragment\n### Why It Matters for Health Policy\n\n- **Personalized medicine**: Who benefits most from treatment?\n- **Resource allocation**: Where should we target interventions?\n- **Equity**: Do effects differ across populations?\n\n::: {.callout-tip}\n## This is Units 3-4\nCausal forests, meta-learners, policy learning.\n:::\n:::\n\n---\n\n## ML for Experimental Design\n\n### Adaptive Experiments\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Traditional RCT**\n\n- Fixed assignment probabilities\n- Equal allocation\n- Static design\n:::\n\n::: {.column width=\"50%\"}\n**Adaptive/ML-Enhanced**\n\n- Response-adaptive randomization\n- Covariate-adaptive allocation\n- Bandits and exploration\n:::\n:::\n\n::: fragment\n### How ML Helps\n\n1. **Variance reduction** via covariate adjustment\n2. **Blocking and stratification** with many covariates\n3. **Adaptive designs** that learn during trial\n4. **Power optimization** using baseline predictions\n\n::: {.callout-tip}\n## This is Unit 1\nDesign-based inference with modern tools.\n:::\n:::\n\n# AI in Your Workflow {.center}\n\n## \"AI in the Loop\" ‚Äî Not \"Human in the Loop\"\n\n::: {.columns}\n::: {.column width=\"60%\"}\n### Human-Driven, AI-Assisted\n\n1. **You** specify the causal question\n2. **You** choose the identification strategy\n3. **AI** assists with implementation\n4. **You** evaluate and interpret results\n5. **You** make the decision\n:::\n\n::: {.column width=\"40%\"}\n### Why It Matters\n\n- AI can't choose your research question\n- AI can hallucinate methods\n- AI doesn't know your context\n- AI can't defend your work\n- **You are responsible**\n:::\n:::\n\n::: {.notes}\nThis distinction is crucial. Many people talk about \"human in the loop\" for AI systems. In research, we flip this: the human drives the process, AI assists. You maintain control and responsibility.\n:::\n\n---\n\n## AI in Causal Analysis: Do's and Don'ts\n\n::: {.columns}\n::: {.column width=\"50%\"}\n### ‚úÖ Good Uses of AI\n\n- Code implementation\n- Debugging syntax errors\n- Explaining methods\n- Generating simulations\n- Formatting output\n:::\n\n::: {.column width=\"50%\"}\n### ‚ùå Risky Uses of AI\n\n- Choosing identification strategy\n- Interpreting results for you\n- Making causal claims\n- Selecting variables\n- \"Just run an analysis\"\n:::\n:::\n\n::: {.callout-important}\n## Course Policy\nYou may use AI tools, but you are responsible for all submitted work. You must understand and be able to explain every line of code and every claim.\n:::\n\n# Course Materials {.center}\n\n## Primary Textbooks (Both FREE!)\n\n::: {.columns}\n::: {.column width=\"50%\"}\n### Chernozhukov et al. (2025)\n*Applied Causal Inference Powered by ML and AI*\n\n[causalml-book.org](https://causalml-book.org/)\n\n- Practitioner-focused\n- Python + R code\n- Industry examples\n:::\n\n::: {.column width=\"50%\"}\n### Wager (2024)\n*Causal Inference: A Statistical Learning Approach*\n\n[Stanford PDF](http://web.stanford.edu/~swager/causal_inf_book.pdf)\n\n- Theoretical foundations\n- Math-forward\n- Research orientation\n:::\n:::\n\n::: {.callout-tip}\n## Reading Strategy\nUse Chernozhukov for implementation, Wager for deeper understanding of the theory.\n:::\n\n---\n\n## Methods Preview\n\n### What You'll Learn\n\n::: {.columns}\n::: {.column width=\"33%\"}\n#### Estimation\n- Double ML\n- AIPW\n- Influence functions\n:::\n\n::: {.column width=\"33%\"}\n#### Heterogeneity\n- Causal forests\n- Meta-learners\n- CATE estimation\n:::\n\n::: {.column width=\"33%\"}\n#### Policy\n- Policy trees\n- Off-policy evaluation\n- Treatment rules\n:::\n:::\n\n::: fragment\n### R Packages\n\n`DoubleML` | `grf` | `policytree` | `did` | `Synth` | `DeclareDesign`\n:::\n\n# This Week {.center}\n\n## This Week's Goals\n\n### By End of Unit 0 (Week 1)\n\n1. ‚úÖ Understand the three-layer causal inference stack\n2. üìê Apply potential outcomes framework\n3. üìä Construct and interpret basic DAGs\n4. üíª Set up reproducible R environment\n5. üî¨ Simulate basic RCT and estimate ATE\n\n---\n\n## Next Session: Session 0.2 (Jan 12)\n\n### Reproducible Research Setup (Remote via Zoom)\n\n- R environment with `renv`\n- Workflow automation with `targets`\n- Introduction to `DeclareDesign`\n- Simulating RCT data in R\n\n::: {.callout-important}\n## Preparation\nInstall R and RStudio before Session 0.2. Instructions in syllabus.\n:::\n\n---\n\n## Reading Assignment\n\n### For Session 0.3 (Thursday)\n\n**Required:**\n\n- [Chernozhukov Ch. 0 (Sneak Peek)](http://chapters.causalml-book.org/CausalML_chap_0.pdf) ‚Äî ~10 pages\n- [Chernozhukov Ch. 2 (Causal Models)](http://chapters.causalml-book.org/CausalML_chap_2.pdf) ‚Äî ~20 pages\n- [Hern√°n & Robins Ch. 1-2](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/) ‚Äî ~18 pages\n\n**Optional:**\n\n- [Brady Neal Ch. 1-2](https://www.bradyneal.com/Introduction_to_Causal_Inference-Dec17_2020-Neal.pdf) (ML-first perspective)\n- [R for Data Science Ch. 1-5](https://r4ds.hadley.nz/) (R refresher)\n\n---\n\n## Summary\n\n### Key Takeaways\n\n1. **Three-layer stack**: Identification ‚Üí Estimation ‚Üí Decision\n2. **Prediction ‚â† Causation**: Different goals require different methods\n3. **Potential outcomes**: $Y(1)$, $Y(0)$, and the fundamental problem\n4. **ML helps**: Nuisance estimation, HTE, adaptive design\n5. **AI in the Loop**: Human-driven, AI-assisted analysis\n6. **This course**: Modern causal ML for health policy\n\n---\n\n## Questions? {.center}\n\n::: {.callout-tip}\n## After Class\nComplete the [Introductory Survey](https://unc.az1.qualtrics.com/jfe/form/SV_07iqDZtdRC5PIJE) by January 15.\n:::\n\n::: {.callout-note}\n## Office Hours\nWednesday 2:00-4:00pm ‚Äî McGavran-Greenberg 1101-D or Zoom\n:::\n\n::: {.notes}\nRecap the key points. Next session we'll get hands-on with R setup and start simulating data.\n:::\n",
    "supporting": [
      "session-0-1-slides_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}